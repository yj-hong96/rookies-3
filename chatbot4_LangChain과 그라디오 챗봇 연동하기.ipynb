{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pyLTgWwvQhV"
   },
   "source": [
    "그라디오 챗봇와 랭체인 LLM 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29624,
     "status": "ok",
     "timestamp": 1739071493071,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "mho6mQWYvUle",
    "outputId": "05496f39-0f87-447e-d46a-0edbf9566171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 설치합니다.\n",
    "%pip install -q gradio \n",
    "# openai 라이브러리를 설치합니다.\n",
    "%pip install -q openai \n",
    "# 랭체인 라이브러리를 설치합니다.\n",
    "%pip install -q langchain \n",
    "# 랭체인 OpenAI 연동 라이브러리를 설치합니다.\n",
    "%pip install -q -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain의 ChatOpenAI가 환경 변수를 자동으로 로드하는 방식\n",
    "* load_dotenv()를 실행하면 .env 파일에 있는 환경 변수가 시스템 환경 변수로 등록됨\n",
    "* LangChain의 ChatOpenAI는 api_key=None일 때 os.getenv(\"OPENAI_API_KEY\")를 자동으로 불러옴\n",
    "* 따라서 api_key를 명시적으로 설정하지 않아도 API 키가 자동으로 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739073587961,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "1eHQ5ThX3KHP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.18\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4273,
     "status": "ok",
     "timestamp": 1739073595715,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "3_Wj7jaE4giS",
    "outputId": "b9e33cb5-b7d6-4080-89eb-7722641b7f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='파이썬은 간결하고 읽기 쉽고 유연한 프로그래밍 언어로, 광범위한 응용 분야에서 사용되는 프로그래밍 언어입니다. Python으로 개발된 소프트웨어는 웹 개발, 데이터 분석, 인공지능, 머신러닝, 자동화 등 다양한 분야에서 사용됩니다. 파이썬은 초보자에게 친숙하며, 쉽게 배우고 사용할 수 있어서 많은 프로그래머들에게 인기가 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 169, 'prompt_tokens': 17, 'total_tokens': 186, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-7adcde07-a7ae-4cb5-b3e3-b1cdcb03bd3a-0' usage_metadata={'input_tokens': 17, 'output_tokens': 169, 'total_tokens': 186, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"파이썬이란?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739024376025,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "gOGwTNy_4xKQ",
    "outputId": "4a056343-7741-4346-9b92-2e9888b200f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API 키를 명시적으로 설정하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='파이썬은 인터프리터 방식으로 동작하는 고급 프로그래밍 언어이다. 발명자인 귀도 반 로섬(Guido van Rossum)에 의해 1991년에 발표되었으며, 파이썬의 주요 특징은 가독성과 간결성, 다양한 라이브러리와 모듈을 지원한다는 것이다. 파이썬은 데이터 분석, 인공지능, 웹 개발, 시스템 자동화 등 다양한 분야에서 널리 사용되고 있다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 17, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a00a702a-b545-4eb1-921f-41121a44788b-0' usage_metadata={'input_tokens': 17, 'output_tokens': 170, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일을 로드\n",
    "load_dotenv()  \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  \n",
    "# 명시적으로 API 키 설정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)  \n",
    "\n",
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"파이썬이란?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "executionInfo": {
     "elapsed": 120391,
     "status": "ok",
     "timestamp": 1739073719232,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "wRX0aUZk7Zul",
    "outputId": "5eba57b6-5fbf-4597-de9a-d473e943d423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr\n",
    "# LangChain 의 ChatOpenAI 를 불러옵니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def chat_respond(message, chat_history):  \n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": message}])\n",
    "    bot_message = response.content\n",
    "    \n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chat_history  \n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:  \n",
    "    chatbot = gr.Chatbot(label=\"채팅창\", type=\"messages\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(chat_respond, [msg, chatbot], [msg, chatbot])  \n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  \n",
    "\n",
    "# 인터페이스를 실행합니다. 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며, '초기화' 버튼을 통해 채팅 기록을 초기화 할 수 있습니다.\n",
    "demo.launch(debug=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXBgDfxg9Bt6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObKSkPPvS7YmfW96AW/9bs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
