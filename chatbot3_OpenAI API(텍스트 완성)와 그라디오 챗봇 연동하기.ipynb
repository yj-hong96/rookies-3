{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24671,
     "status": "ok",
     "timestamp": 1739005658712,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "nHP72RCZz63S",
    "outputId": "478a113c-ed3a-4047-c599-4674f54adcd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 설치합니다.\n",
    "%pip install -q gradio \n",
    "# openai 라이브러리를 설치합니다.\n",
    "%pip install -q openai\n",
    "# .env 환경변수 로드하는 python-dotenv 라이브러리를 설치합니다.\n",
    "%pip show python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6004,
     "status": "ok",
     "timestamp": 1739005718338,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "Kv7ZmttR0AJZ",
    "outputId": "950e2688-d164-4aa0-80a5-90808443c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61.1\n",
      "5.15.0\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 라이브러리를 불러옵니다.\n",
    "import openai \n",
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr  \n",
    "\n",
    "print(openai.__version__)\n",
    "print(gr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkJr05D60VcE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR2K9qKg04vI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 할당합니다.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "id": "KXqZpkHV1NQw",
    "outputId": "af9d5e0f-4793-4e10-8bc6-b8940af1d759"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vega2\\anaconda3\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B6E2wvmF8B9EYrDEbJW015OrKtHUA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Langchain은 언어를 이해하고 처리하는 인공지능 기술을 활용하여 다양한 언어 간 통역 및 번역 기능을 제공하는 플랫폼입니다. Langchain은 다국어 의사소통을 원활하게 돕는데 사용될 수 있으며, 글로벌 업무나 소통에 유용하게 활용될 수 있는 기술입니다.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740823662, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=128, prompt_tokens=28, total_tokens=156, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def chat_respond(message, chat_history):  \n",
    "    # 새 클라이언트 객체 생성\n",
    "    client = openai.OpenAI()  \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # 사용할 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    # 응답 Json에서 출력 텍스트를 지정합니다.\n",
    "    bot_message = response.choices[0].message.content \n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chat_history.append((message, bot_message))  \n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chat_history  \n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:  \n",
    "    chatbot = gr.Chatbot(label=\"채팅창\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 chat_respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(chat_respond, [msg, chatbot], [msg, chatbot])  \n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  \n",
    "\n",
    "# 인터페이스를 실행합니다. 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며, \n",
    "# '초기화' 버튼을 통해 채팅 기록을 초기화 할 수 있습니다.\n",
    "demo.launch()\n",
    "#demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRMcC1xk66pa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnbNsawB5gZIurrEsQgwwR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
