{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5434d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70202ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServeëŠ” ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff33d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002078E36A510> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002078E36AF90> root_client=<openai.OpenAI object at 0x000002078E207620> root_async_client=<openai.AsyncOpenAI object at 0x000002078E36ACF0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1a5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangServeëŠ” ê°œë°œìê°€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. LangServeë¥¼ ì‚¬ìš©í•˜ë©´ ê°œë°œìëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì‰½ê²Œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nLangServeì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **ëª¨ë¸ ë°°í¬**: LangServeë¥¼ ì‚¬ìš©í•˜ë©´ ê°œë°œìëŠ” í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ë©´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **API ì„œë²„**: LangServeëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ëª¨ë¸ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë°œìëŠ” ëª¨ë¸ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜, ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜, ë˜ëŠ” ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. **ëª¨ë¸ ê´€ë¦¬**: LangServeëŠ” ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì§€ì›í•˜ì—¬ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n4. **í™•ì¥ì„±**: LangServeëŠ” ìˆ˜í‰ í™•ì¥ì„±ì„ ì§€ì›í•˜ì—¬ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n5. **ë³´ì•ˆ**: LangServeëŠ” ë°ì´í„° ì•”í˜¸í™”, ì ‘ê·¼ ì œì–´ ë“±ì˜ ë³´ì•ˆ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•©ë‹ˆë‹¤.\\n\\n6. **ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›**: LangServeëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì„ ì§€ì›í•˜ë©°, íŠ¹íˆ Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ê¸´ë°€í•˜ê²Œ í†µí•©ë©ë‹ˆë‹¤.\\n\\nLangServeë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n* ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* í™•ì¥ì„±ê³¼ ë³´ì•ˆì´ ë›°ì–´ë‚©ë‹ˆë‹¤.\\n\\nLangServeì˜ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n* ì±—ë´‡ ê°œë°œ: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ì±—ë´‡ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* ì–¸ì–´ ë²ˆì—­: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ë²ˆì—­ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* í…ìŠ¤íŠ¸ ìš”ì•½: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìš”ì•½ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ê¸°ì‚¬ ë˜ëŠ” ë¬¸ì„œì˜ ìš”ì•½ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nê²°ë¡ ì ìœ¼ë¡œ, LangServeëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë°œìëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 475, 'prompt_tokens': 30, 'total_tokens': 505, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.300551306, 'prompt_time': 0.003034687, 'completion_time': 1.154676738, 'total_time': 1.157711425}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-ac5bad85-9f10-4e4b-b446-5a908d65bdb7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--3b699040-9e27-47c8-8a24-698fbeed6ec9-0' usage_metadata={'input_tokens': 30, 'output_tokens': 475, 'total_tokens': 505, 'input_token_details': {}, 'output_token_details': {}}\n",
      "ì‘ë‹µ: LangServeëŠ” ê°œë°œìê°€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. LangServeë¥¼ ì‚¬ìš©í•˜ë©´ ê°œë°œìëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì‰½ê²Œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "LangServeì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ëª¨ë¸ ë°°í¬**: LangServeë¥¼ ì‚¬ìš©í•˜ë©´ ê°œë°œìëŠ” í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ë©´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **API ì„œë²„**: LangServeëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ëª¨ë¸ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë°œìëŠ” ëª¨ë¸ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜, ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜, ë˜ëŠ” ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ê´€ë¦¬**: LangServeëŠ” ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì§€ì›í•˜ì—¬ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **í™•ì¥ì„±**: LangServeëŠ” ìˆ˜í‰ í™•ì¥ì„±ì„ ì§€ì›í•˜ì—¬ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ë³´ì•ˆ**: LangServeëŠ” ë°ì´í„° ì•”í˜¸í™”, ì ‘ê·¼ ì œì–´ ë“±ì˜ ë³´ì•ˆ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›**: LangServeëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì„ ì§€ì›í•˜ë©°, íŠ¹íˆ Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ê¸´ë°€í•˜ê²Œ í†µí•©ë©ë‹ˆë‹¤.\n",
      "\n",
      "LangServeë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "* ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* í™•ì¥ì„±ê³¼ ë³´ì•ˆì´ ë›°ì–´ë‚©ë‹ˆë‹¤.\n",
      "\n",
      "LangServeì˜ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "* ì±—ë´‡ ê°œë°œ: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ì±—ë´‡ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* ì–¸ì–´ ë²ˆì—­: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ë²ˆì—­ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* í…ìŠ¤íŠ¸ ìš”ì•½: LangServeë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìš”ì•½ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ê¸°ì‚¬ ë˜ëŠ” ë¬¸ì„œì˜ ìš”ì•½ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, LangServeëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë°œìëŠ” ì–¸ì–´ ëª¨ë¸ì„ API ì„œë²„ë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬, ì—…ë°ì´íŠ¸, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbd5a1",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLMì„ Chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c34c649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\\n    ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d392dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbba4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084bfec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ë˜ì˜ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê±°ë‚˜ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , íŒ¨í„´ì„ ë°œê²¬í•˜ë©°, ê·œì¹™ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì¥ ê¸°ë³¸ì ì¸ í•™ìŠµ ì›ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ë§ì€ ì–‘ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ëª¨ë¸ì— ì…ë ¥ë˜ê¸° ì „ì— ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ë°ì´í„°ì˜ ì¡ìŒì„ ì œê±°í•˜ê±°ë‚˜, ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” ë“±ì˜ ì‘ì—…ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì„ íƒ**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ ì¢…ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹ì—ëŠ” í•©ì„±ê³± ì‹ ê²½ë§(CNN), ìì—°ì–´ ì²˜ë¦¬ì—ëŠ” ìˆœí™˜ ì‹ ê²½ë§(RNN) ë˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë“±ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **í•™ìŠµ**: ì„ íƒëœ ëª¨ë¸ì— ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì—¬ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì¸ì‹í•˜ê³ , ì´ì— ë§ì¶° íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì€ ë³´í†µ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì´ë£¨ì–´ì§€ë©°, ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ê°€ ì¡°ì •ë©ë‹ˆë‹¤.\n",
      "\n",
      "5. **í‰ê°€**: í•™ìŠµì´ ì™„ë£Œëœ í›„, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë©°, ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„, ì˜¤ì°¨ìœ¨ ë“±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **íŠœë‹**: ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì„ ê²½ìš°, í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ëŠ” ë“±ì˜ íŠœë‹ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì–´ë¦° ì•„ì´ì—ê²Œ ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ì˜ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ê³  ì´ ë‘˜ì„ êµ¬ë³„í•˜ë¼ê³  í•˜ë©´, ì²˜ìŒì—ëŠ” êµ¬ë³„í•˜ì§€ ëª»í•  ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ ë²ˆ ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ë¥¼ ë³´ì—¬ì£¼ê³ , ì´ê²ƒì´ ì‚¬ê³¼ì´ê³ , ì´ê²ƒì´ ë°”ë‚˜ë‚˜ë¼ê³  ì„¤ëª…í•´ ì£¼ë©´, ì•„ì´ëŠ” ì–´ëŠ ìˆœê°„ë¶€í„°ëŠ” ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ë¥¼ êµ¬ë³„í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë„ ì´ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ëª¨ë¸ì—ê²Œ ë§ì€ ë°ì´í„°ë¥¼ ì œê³µí•˜ê³ , ì´ê²ƒì´ ì–´ë–¤ ê²ƒì¸ì§€ë¥¼ ì„¤ëª…í•´ ì£¼ë©´, ëª¨ë¸ì€ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ì‚¬ê³¼ì™€ ë°”ë‚˜ë‚˜ì˜ ì‚¬ì§„ì„ êµ¬ë³„í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í•™ìŠµ ì›ë¦¬ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìœ¼ë©°, ììœ¨ ì£¼í–‰ ìë™ì°¨, ì˜ë£Œ ì§„ë‹¨, ì–¸ì–´ ë²ˆì—­ ë“± ë§ì€ ì‘ìš© ë¶„ì•¼ì—ì„œ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33153ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \": LangChainì˜ Products(ì œí’ˆ)ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”? ì˜ˆë¥¼ ë“¤ì–´ LangSmith, LangServe ê°™ì€ Productê°€ ìˆì–´\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d50087",
   "metadata": {},
   "source": [
    "\n",
    "###Runnableì˜ stream() í•¨ìˆ˜ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfabd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "    \n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "    #print(answer)\n",
    "    for token in answer:\n",
    "        # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a759f26",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* ì²«ë²ˆì§¸ Chainì˜ ì¶œë ¥ì´, ë‘ë²ˆì§¸ Chainì˜ ì…ë ¥ì´ ëœë‹¤.\n",
    "* ë‘ê°œì˜ Chainê³¼ Prompt + OutputParserë¥¼ LCELë¡œ ì—°ê²°í•˜ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf368a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001BD5B7D96D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001BD5B7DB750> root_client=<openai.OpenAI object at 0x000001BD5B7DB110> root_async_client=<openai.AsyncOpenAI object at 0x000001BD5B7DB890> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 15ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ì…ë ¥ ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "    response = chain2.invoke({\"genre\": \"ì„±ì¸\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1eab14",
   "metadata": {},
   "source": [
    "## PromptTemplate ì—¬ëŸ¬ê°œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"ì˜ì–´\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"ì˜ì–´\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1595b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 2 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'llama*4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama*4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3747ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) #AIMessage\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da13a8",
   "metadata": {},
   "source": [
    "### System_messagePromptTemplate\n",
    "* HumanMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092be190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ {topic} ì „ë¬¸ê°€ ì…ë‹ˆë‹¤ë‹¤. ëª…í™•í•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"ë”¥ëŸ¬ë‹ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19efed56",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* í”„ë¡¬í”„íŠ¸ì—ì„œ ì˜ˆì‹œë¥¼ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39112b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### íƒœì–‘ê³„ì˜ í–‰ì„±\n",
      "\n",
      "1. **ìˆ˜ì„±**: íƒœì–‘ê³¼ ê°€ì¥ ê°€ê¹Œìš´ í–‰ì„±ìœ¼ë¡œ, ë§¤ìš° ì‘ì€ í¬ê¸°ì™€ ë†’ì€ ì˜¨ë„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "2. **ê¸ˆì„±**: ë°ê³  ëœ¨ê±°ìš´ í–‰ì„±ìœ¼ë¡œ, ê°•í•œ ì˜¨ì‹¤ íš¨ê³¼ë¡œ ì¸í•´ í‘œë©´ ì˜¨ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.\n",
      "3. **ì§€êµ¬**: ìƒëª…ì²´ê°€ ì¡´ì¬í•˜ëŠ” ìœ ì¼í•œ í–‰ì„±ìœ¼ë¡œ, ëŒ€ê¸° êµ¬ì„±ê³¼ ë¬¼ì´ ìˆì–´ ìƒëª… ìœ ì§€ì— ì í•©í•©ë‹ˆë‹¤.\n",
      "4. **í™”ì„±**: ë¶‰ì€ í–‰ì„±ìœ¼ë¡œ, ê³¼ê±°ì— ë¬¼ì´ ìˆì—ˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©°, í˜„ì¬ëŠ” ì•”ì„ê³¼ ëª¨ë˜ë¡œ ë®ì—¬ ìˆìŠµë‹ˆë‹¤.\n",
      "5. **ëª©ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ í° í–‰ì„±ìœ¼ë¡œ, ê°€ìŠ¤ ê±°ì¸ì´ë©° ìˆ˜ë§ì€ ìœ„ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "6. **í† ì„±**: ì•„ë¦„ë‹¤ìš´ ë°˜ì§€ë¡œ ìœ ëª…í•œ ê°€ìŠ¤ ê±°ì¸ìœ¼ë¡œ, ë§ì€ ìœ„ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "7. **ì²œì™•ì„±**: ì–¼ìŒ ê±°ì¸ìœ¼ë¡œ, ìì „ì¶•ì´ ê¸°ìš¸ì–´ì ¸ ìˆì–´ ê·¹ë‹¨ì ì¸ ê³„ì ˆ ë³€í™”ë¥¼ ê²½í—˜í•©ë‹ˆë‹¤.\n",
      "8. **í•´ì™•ì„±**: ê°€ì¥ ë¨¼ í–‰ì„±ìœ¼ë¡œ, ê°•í•œ ë°”ëŒê³¼ ê¹Šì€ í‘¸ë¥¸ìƒ‰ì„ ë ëŠ” ëŒ€ê¸°ì¸µì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "#result = chain.invoke({\"input\": \"ì–‘ì ì–½í˜ì´ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf5e1d",
   "metadata": {},
   "source": [
    "### PartialPromptTemplate\n",
    "* í”„ë¡¬í”„íŠ¸ì˜ ì…ë ¥ ê°’ì— í•¨ìˆ˜ í˜¸ì¶œ ì´ë‚˜ ì™¸ë¶€ APIë¥¼ í˜¸ì¶œí•œ ë™ì ì¸ ê°’ì„ ëŒ€ì…í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceb891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ê²¨ìš¸\n",
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: <bound method ChatPromptTemplate.from_template of <class 'langchain_core.prompts.chat.ChatPromptTemplate'>>\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ê²¨ìš¸ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \n",
      " ê²¨ìš¸ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ê·¹ê´‘**: ê·¹ê´‘ì€ íƒœì–‘í’ì´ ì§€êµ¬ ìê¸°ì¥ì— ì˜í•´ ê·¹ì§€ë°©ìœ¼ë¡œ ëŒë ¤ê°€ë©´ì„œ ëŒ€ê¸° ì…ìì™€ ì¶©ëŒí•˜ì—¬ ë°œìƒí•˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì´ ì¶©ëŒë¡œ ì¸í•´ ëŒ€ê¸° ì…ìë“¤ì´ ì—ë„ˆì§€ë¥¼ ì–»ê³  ë¹›ì„ ë°©ì¶œí•˜ê²Œ ë˜ëŠ”ë°, ì´ ë¹›ì´ ê·¹ê´‘ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ê·¹ê´‘ì€ ì£¼ë¡œ ë¶ê·¹ê³¼ ë‚¨ê·¹ ì§€ì—­ì—ì„œ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ê²¨ìš¸ì— ë”ìš± ì„ ëª…í•˜ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
      "2.  **ë¹™í•˜**: ë¹™í•˜ëŠ” ê·¹ì§€ë°©ì´ë‚˜ ê³ ì‚° ì§€ì—­ì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ëˆˆì´ ìŒ“ì—¬ ì–¼ì–´ë¶™ì€ ì–¼ìŒ ë©ì–´ë¦¬ì…ë‹ˆë‹¤. ë¹™í•˜ëŠ” ì§€êµ¬ì˜ ê¸°í›„ ë³€í™”ì™€ ê´€ë ¨ì´ ìˆìœ¼ë©°, ê²¨ìš¸ì— ë”ìš± ì»¤ì§€ê³  ë‘êº¼ì›Œì§‘ë‹ˆë‹¤.\n",
      "3.  **ì„±ì¸µê¶Œ ì˜¤ì¡´ êµ¬ë©**: ê²¨ìš¸ì— ì˜¤ì¡´ êµ¬ë©ì´ í˜•ì„±ë˜ëŠ” ì´ìœ ëŠ” ì„±ì¸µê¶Œì—ì„œ ì˜¤ì¡´ì„ íŒŒê´´í•˜ëŠ” ë¬¼ì§ˆë“¤ì´ ê·¹ì§€ë°©ì—ì„œ ì§‘ì¤‘ë˜ì–´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¼ì§ˆë“¤ì€ ì£¼ë¡œ ì—¼ì†Œì™€ ë¸Œë¡¬ í™”í•©ë¬¼ë¡œ, ì´ë“¤ì€ ê·¹ì§€ë°©ì—ì„œ ê·¹ì €ì˜¨ìœ¼ë¡œ ì¸í•´ ì–¼ì–´ë¶™ì–´ ìˆëŠ” êµ¬ë¦„ ì…ì ìœ„ì— ì‘ì¶•ë©ë‹ˆë‹¤. ì´ êµ¬ë¦„ ì…ìë“¤ì€ ê·¹ì§€ë°©ì˜ ë°¤ ë™ì•ˆ ê·¹ì‹¬í•œ ì¶”ìœ„ë¡œ ì¸í•´ í˜•ì„±ë˜ë©°, ì´ êµ¬ë¦„ ì…ì ìœ„ì—ì„œ ì˜¤ì¡´ì„ íŒŒê´´í•˜ëŠ” í™”í•™ ë°˜ì‘ì´ í™œë°œí•˜ê²Œ ì¼ì–´ë‚˜ ì˜¤ì¡´ êµ¬ë©ì´ í˜•ì„±ë©ë‹ˆë‹¤. ì˜¤ì¡´ êµ¬ë©ì€ ìì™¸ì„  ì°¨ë‹¨ ì—­í• ì„ í•˜ëŠ” ì˜¤ì¡´ì¸µì— êµ¬ë©ì´ ëš«ë¦¬ëŠ” í˜„ìƒìœ¼ë¡œ, ìì™¸ì„ ì— ë¯¼ê°í•œ ìƒë¬¼ì—ê²Œ í•´ë¥¼ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í˜„ìƒë“¤ì€ ì§€êµ¬ê³¼í•™ì—ì„œ ì¤‘ìš”í•œ ì—°êµ¬ ì£¼ì œì´ë©°, ê¸°í›„ ë³€í™”ì™€ ì§€êµ¬ í™˜ê²½ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì…ë‹ˆë‹¤.\",\n",
    "#     input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "#     partial_variables={\"season\": get_current_season(\"south\")}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    "# )\n",
    "\n",
    "season = get_current_season(\"south\")\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season}\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "chain = (\n",
    "    {\"season\": lambda x: season}\n",
    "    | prompt\n",
    "    | model\n",
    "    |StrOutputParser()\n",
    ")\n",
    "result = chain.invoke({})\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ í”„ë¡¬í”„íŠ¸: {prompt}\") #ë™ì¼ -> {prompt.from_template\"}\n",
    "print(f\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \\n {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b0e06",
   "metadata": {},
   "source": [
    "### 2. APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ë™ì ì¸ ê°’ì„  partial variableë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b32b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={'info': '1ë‹¬ëŸ¬ = 1365.14ì›'} template='í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ëŒ€ì±…ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# {info} ë³€ìˆ˜ì— APIì—ì„œ ë°›ì€ í™˜ìœ¨ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ë°˜ì˜\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ëŒ€ì±…ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1da566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1365.14ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ëŒ€ì±…ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ## 1. í˜„ì¬ í™˜ìœ¨ ìƒí™©\n",
      "2024ë…„ 4ì›” 5ì¼, 1ë‹¬ëŸ¬ = 1,365.14ì›ì…ë‹ˆë‹¤. ìµœê·¼ í™˜ìœ¨ì€ ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©, ë¯¸êµ­ì˜ í†µí™” ì •ì±…, í•œêµ­ì˜ ìˆ˜ì¶œì… ë™í–¥ ë“± ë‹¤ì–‘í•œ ìš”ì¸ì— ì˜í•´ ì˜í–¥ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 2. í•œêµ­ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥\n",
      "\n",
      "#### (1) ìˆ˜ì¶œì…\n",
      "- **ìˆ˜ì¶œ**: ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ì˜ ìˆ˜ì¶œì„ ì´‰ì§„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›í™” ì•½ì„¸ë¡œ ì¸í•´ í•œêµ­ ìƒí’ˆì˜ ê°€ê²©ì´ í•´ì™¸ ì‹œì¥ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ì €ë ´í•´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ìë™ì°¨, ë°˜ë„ì²´, ì² ê°• ë“± ì£¼ìš” ìˆ˜ì¶œ ì‚°ì—…ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ìˆ˜ì…**: ë°˜ëŒ€ë¡œ, ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì… ë¬¼ê°€ë¥¼ ìƒìŠ¹ì‹œì¼œ êµ­ë‚´ ë¬¼ê°€ ìƒìŠ¹ ì••ë ¥ì„ ê°€ì¤‘ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ìœ , ì›ìì¬, ì „ìì œí’ˆ ë“± ìˆ˜ì…ì— ì˜ì¡´í•˜ëŠ” ì‚°ì—…ì˜ ë¹„ìš© ë¶€ë‹´ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (2) ë¬¼ê°€ ìƒìŠ¹\n",
      "- ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì… ë¬¼ê°€ ìƒìŠ¹ì„ í†µí•´ ì†Œë¹„ì ë¬¼ê°€ ì§€ìˆ˜ë¥¼ ìƒìŠ¹ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°€ê³„ì˜ ì‹¤ì§ˆì†Œë“ ê°ì†Œë¥¼ ì´ˆë˜í•˜ê³ , ì†Œë¹„ ì‹¬ë¦¬ë¥¼ ìœ„ì¶•ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (3) ê¸ˆìœµ ì‹œì¥\n",
      "- ì›í™” ì•½ì„¸ëŠ” ì™¸êµ­ì¸ íˆ¬ììë“¤ì—ê²Œ í•œêµ­ ìì‚°(ì£¼ì‹, ì±„ê¶Œ ë“±)ì˜ ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì™¸êµ­ì¸ ìê¸ˆì˜ ìœ ì¶œë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë©°, êµ­ë‚´ ê¸ˆìœµ ì‹œì¥ì˜ ë³€ë™ì„±ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (4) ê¸°ì—… ì‹¤ì \n",
      "- **ìˆ˜ì¶œ ê¸°ì—…**: í™˜ìœ¨ ìƒìŠ¹ìœ¼ë¡œ ì¸í•´ ìˆ˜ì¶œ ê¸°ì—…ì˜ ì‹¤ì ì´ ê°œì„ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì›ìì¬ë¥¼ ìˆ˜ì…í•˜ëŠ” ê¸°ì—…ë“¤ì€ ë¹„ìš© ë¶€ë‹´ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ë‚´ìˆ˜ ê¸°ì—…**: ë‚´ìˆ˜ ì¤‘ì‹¬ ê¸°ì—…ë“¤ì€ ë†’ì€ ë¬¼ê°€ì— ë”°ë¥¸ ì†Œë¹„ ìœ„ì¶•ìœ¼ë¡œ ë¶€ì •ì ì¸ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 3. í–¥í›„ ëŒ€ì±…\n",
      "\n",
      "#### (1) í†µí™” ì •ì±…\n",
      "- **í•œêµ­ì€í–‰**: ë†’ì€ ë¬¼ê°€ ìƒìŠ¹ë¥ ê³¼ í™˜ìœ¨ ë³€ë™ì„±ì„ ê³ ë ¤í•˜ì—¬, ê¸ˆë¦¬ ì¸ìƒ ë“± ê¸´ì¶• í†µí™” ì •ì±…ì„ ì‹œí–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¬¼ê°€ ì•ˆì •ê³¼ ê¸ˆìœµ ì‹œì¥ì˜ ì•ˆì •ì„±ì„ í™•ë³´í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (2) ì¬ì • ì •ì±…\n",
      "- **ì •ë¶€**: ìˆ˜ì¶œ ì§€ì› ì •ì±…ì„ ê°•í™”í•˜ê±°ë‚˜, ë¬¼ê°€ ì•ˆì •í™” ëŒ€ì±…ì„ ë§ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìˆ˜ì¶œ ë³´ì¡°ê¸ˆ ì§€ì›, ì›ìì¬ ê°€ê²© ì•ˆì •í™” ëŒ€ì±…, ìƒí•„í’ˆ ê°€ê²© í†µì œ ë“± ë‹¤ì–‘í•œ ì •ì±…ì„ ì‹œí–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (3) ì™¸í™˜ ì‹œì¥ ê°œì…\n",
      "- í•œêµ­ì€í–‰ì€ ì™¸í™˜ ì‹œì¥ì—ì„œ ë‹¬ëŸ¬ë¥¼ ë§¤ì…í•˜ê±°ë‚˜ ë§¤ë„í•˜ì—¬ í™˜ìœ¨ì„ ì•ˆì •í™”ì‹œí‚¤ëŠ” ë°©ì•ˆì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” í•œê³„ê°€ ìˆìœ¼ë©°, ì‹œì¥ ì›ë¦¬ì— ì˜í•´ í™˜ìœ¨ì´ ê²°ì •ë˜ëŠ” ê¸€ë¡œë²Œ ê¸ˆìœµ ì‹œì¥ì—ì„œ íš¨ê³¼ì ì¸ì§€ ì—¬ë¶€ëŠ” ë…¼ë€ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### (4) êµ¬ì¡°ì  ê°œì„ \n",
      "- ì¥ê¸°ì ìœ¼ë¡œëŠ” í•œêµ­ ê²½ì œì˜ êµ¬ì¡°ì  ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìˆ˜ì¶œ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê³ , ë‚´ìˆ˜ ì‹œì¥ì„ í™œì„±í™”í•˜ëŠ” ì •ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ, ì›ìì¬ ìˆ˜ì… ì˜ì¡´ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•´ êµ­ë‚´ ìƒì‚°ì„ í™•ëŒ€í•˜ê³ , ëŒ€ì²´ ìˆ˜ì…ì²˜ë¥¼ ëª¨ìƒ‰í•˜ëŠ” ë“±ì˜ ì „ëµì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "### 4. ê²°ë¡ \n",
      "í˜„ì¬ì˜ ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ ê²½ì œì— ë³µí•©ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ì¶œì—ëŠ” ê¸ì •ì ì´ì§€ë§Œ, ë¬¼ê°€ ìƒìŠ¹ê³¼ ê¸ˆìœµ ì‹œì¥ì˜ ë³€ë™ì„± ì¦ê°€ ë“± ë¶€ì •ì ì¸ ì˜í–¥ë„ ì¡´ì¬í•©ë‹ˆë‹¤. í–¥í›„ ëŒ€ì±…ìœ¼ë¡œëŠ” í†µí™” ì •ì±…, ì¬ì • ì •ì±…, ì™¸í™˜ ì‹œì¥ ê°œì…, êµ¬ì¡°ì  ê°œì„  ë“± ë‹¤ê°ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ê²½ì œì˜ ì•ˆì •ì„±ê³¼ ì§€ì† ê°€ëŠ¥í•œ ì„±ì¥ì„ ìœ„í•´, ì •ë¶€ì™€ í•œêµ­ì€í–‰ì˜ ì ê·¹ì ì¸ ëŒ€ì‘ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# LLM ëª¨ë¸ ì„¤ì • (GPT-4o-mini ì‚¬ìš©)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ”¹ í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
