{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1: 카페 메뉴 도구 호출 체인 구현\n",
    "\n",
    "import re\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce343c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 환경 설정\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9178d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"./db/cafe_db\")\n",
    "    \n",
    "    return cafe_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928297f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "# 웹 검색 도구\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f7469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위키피디아 검색 도구\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    \n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "    ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47bacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-4-scout-17b-16e-instruct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45789a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2228\\4223853708.py:6: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  wiki_summary = summary_chain.as_tool(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm\n",
    ")\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f99bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 카페 메뉴 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"./db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccfc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a663d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def cafe_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # 첫 번째 LLM 호출로 도구 사용 결정\n",
    "    ai_msg = llm_with_tools.invoke(user_input, config=config)\n",
    "    \n",
    "    # 도구 실행\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    # 최종 답변 생성을 위한 프롬프트\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful cafe assistant. Provide accurate information based on the search results.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", ai_msg.content if ai_msg.content else \"도구를 사용하여 정보를 검색했습니다.\"),\n",
    "        (\"human\", \"검색 결과: {tool_results}\")\n",
    "    ])\n",
    "    \n",
    "    # 도구 결과를 문자열로 변환\n",
    "    tool_results_str = \"\\n\\n\".join([str(msg.content) for msg in tool_msgs])\n",
    "    \n",
    "    # 최종 답변 생성\n",
    "    final_chain = final_prompt | llm\n",
    "    return final_chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_results\": tool_results_str\n",
    "    }, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff0be59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\n",
      "db_search_cafe_func: \n",
      "{'name': 'db_search_cafe_func', 'args': {'query': '아메리오노 가격'}, 'id': '5ev3c1342', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': 'Americano 유래'}, 'id': 'jcnv2y5v8', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "질문: 아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\n",
      "답변: 아메리카노의 가격은 4,500원입니다.\n",
      "\n",
      "아메리카노의 유래는 1940년대 이탈리아에 있습니다. 2차 세계 대전 당시 이탈리아에 주둔하던 미군이 에스프레소에 뜨거운 물을 넣어 마셨는데, 이것이 아메리카노의 시작입니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 벡터 DB 생성 (최초 1회만 실행)\n",
    "    try:\n",
    "        create_cafe_vector_db()\n",
    "        print(\"카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"벡터 DB 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 질문에 답변\n",
    "    query = \"아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\"\n",
    "    response = cafe_search_chain.invoke(query)\n",
    "    \n",
    "    print(\"질문:\", query)\n",
    "    print(\"답변:\", response.content)                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
