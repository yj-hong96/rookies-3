{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1532373",
   "metadata": {},
   "source": [
    "### 1-1ë²ˆ ê¸°ë³¸ ì²´ì¸ ë§Œë“¤ê¸° -AI ìš”ë¦¬ì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3feb0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f98dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5c5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ìš”ë¦¬ì‚¬ ì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ìš”ë¦¬ì‚¬ ì…ë‹ˆë‹¤.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"ê³„ë€ê³¼ ë°¥ ê¹€ì¹˜ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…ê³¼ ìŒì‹ì„ ì¶”ì²œí•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de31bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000250C93C7890> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000250C93C7C50> root_client=<openai.OpenAI object at 0x00000250C93C5E50> root_async_client=<openai.AsyncOpenAI object at 0x00000250C93C7390> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c975600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ê³„ë€ê³¼ ë°¥, ê¹€ì¹˜ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¡œ 'ê³„ë€ ê¹€ì¹˜ë°¥'ì„ ì¶”ì²œí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì¬ë£Œ ì¤€ë¹„**: ê³„ë€ 2ê°œ, ë°¥ 1ê³µê¸°, ê¹€ì¹˜ 1/2ì»µ, ì°¸ê¸°ë¦„ 1í‹°ìŠ¤í‘¼, ì†Œê¸ˆ 1/2í‹°ìŠ¤í‘¼, í›„ì¶” 1/4í‹°ìŠ¤í‘¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
      "2.  **ê¹€ì¹˜ ë‹¤ë“¬ê¸°**: ê¹€ì¹˜ë¥¼ ì˜ê²Œ ì°ì–´ì£¼ì„¸ìš”. \n",
      "3.  **ê³„ë€ í’€ê¸°**: ê³„ë€ì„ ê¹¨ëœ¨ë ¤ ê·¸ë¦‡ì— ë„£ê³ , ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•œ ë’¤ ì˜ í’€ì–´ì¤ë‹ˆë‹¤.\n",
      "4.  **ê³„ë€ í”„ë¼ì´**: íŒ¬ì— ì°¸ê¸°ë¦„ì„ ë‘ë¥´ê³  ê³„ë€ì„ ë„£ì–´ ìŠ¤í¬ë¨ë¸” ì—ê·¸ì²˜ëŸ¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. \n",
      "5.  **ë°¥ê³¼ ê¹€ì¹˜ ì„ê¸°**: ë°¥ì— ì°ì–´ ë†“ì€ ê¹€ì¹˜ë¥¼ ë„£ê³  ì˜ ì„ì–´ì¤ë‹ˆë‹¤.\n",
      "6.  **ì™„ì„±**: ì´ì œ í”„ë¼ì´íŒ¬ì— ë§Œë“¤ì–´ ë†“ì€ ê³„ë€ê³¼ ê¹€ì¹˜ë°¥ì„ ì„ì–´ì¤ë‹ˆë‹¤. \n",
      "7.  **ë§ˆë¬´ë¦¬**: ë§›ìˆëŠ” ê³„ë€ ê¹€ì¹˜ë°¥ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a2c97",
   "metadata": {},
   "source": [
    "### 1-2 2ë‹¨ê³„ ì²´ì¸ ë§Œë“¤ê¸° - ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "* ë¬¸ì œ ì„¤ëª… : ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” ì¥ë¥´ë¥¼ ì…ë ¥í•˜ë©´, ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ê·¸ì˜í™”ì˜ ì •ë³´(ê°ë…, ì¤„ê±°ë¦¬, ë“±ì¥ì¸ë¬¼)ë“¤ì„ ì•Œë ¤ì£¼ëŠ” 2ë‹¨ê³„ ì²´ì¸ì„ êµ¬í˜„í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "647e7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82efb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì˜í™”ê°í‰ì‚¬ ì…ë‹ˆë‹¤. ì¥ë¥´ì— ë§ëŠ” ìµœê³ ì˜ ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ì˜í™”ê°í‰ì‚¬ ì…ë‹ˆë‹¤. ì¥ë¥´ì— ë§ëŠ” ìµœê³ ì˜ ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78afa474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000250C96CB020> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000250C96CA8A0> root_client=<openai.OpenAI object at 0x00000250C96CB110> root_async_client=<openai.AsyncOpenAI object at 0x00000250C96CAD50> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#\n",
    "prompt3 = ChatPromptTemplate.from_template(\"{movie}  ê°ë…ì´ ëˆ„êµ¬ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c63673a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ ì¶”ì²œ ì˜í™”: ìŠ¤ë¦´ëŸ¬ ì˜í™” ì¤‘ 'ì˜¬ë“œ ë³´ì´'(2003)ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜¬ë“œ ë³´ì´ëŠ” í•œêµ­ ì˜í™”ê³„ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì˜í™” ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ì£¼ì¸ê³µì´ 15ë…„ê°„ ê°ê¸ˆëœ ì±„ë¡œ ê¸°ì–µì„ ìƒê³ , ê·¸ í›„ ê¸°ì–µì„ ë˜ì°¾ê³  ë³µìˆ˜ë¥¼ ì¤€ë¹„í•˜ëŠ” ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ ì˜í™”ëŠ” ì‹¬ë¦¬ ìŠ¤ë¦´ëŸ¬ ì¥ë¥´ì— ì†í•˜ë©°, ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ìŠ¤í† ë¦¬ì™€ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ë§ì€ íŒ¬ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " ì¶”ì²œí•˜ëŠ” ì˜í™”ëŠ” 'ì˜¬ë“œ ë³´ì´'(2003)ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ì¸ê³µì€ 15ë…„ê°„ ê°ê¸ˆëœ ì±„ë¡œ ê¸°ì–µì„ ìƒê³ , ê°ê¸ˆëœ ì´ìœ ë‚˜ ìì‹ ì˜ ê³¼ê±°ì— ëŒ€í•´ ì „í˜€ ëª¨ë¥´ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì–µì„ ë˜ì°¾ì€ í›„, ê·¸ëŠ” ìì‹ ì˜ ê°ê¸ˆê³¼ ë³µìˆ˜ë¥¼ ì¤€ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ìŠ¤í† ë¦¬ì™€ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ë§ì€ íŒ¬ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ¥ ê°ë…: ì˜¬ë“œ ë³´ì´ì˜ ê°ë…ì€ ë°•ì°¬ìš±ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ì •ì˜\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "chain3 = prompt3 | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "output1 = chain1.invoke({\"genre\": \"ìŠ¤ë¦´ëŸ¬\"})      # ì¥ë¥´ë¡œ ì˜í™” ì¶”ì²œ\n",
    "output2 = chain2.invoke({\"movie\": output1})       # ì¶”ì²œ ì˜í™”ë¡œ ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "output3 = chain3.invoke({\"movie\": output1})       # ì¶”ì²œ ì˜í™”ì˜ ê°ë… ì •ë³´\n",
    "\n",
    "print(\"ğŸ¬ ì¶”ì²œ ì˜í™”:\", output1)\n",
    "print(\"ğŸ“ ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", output2)\n",
    "print(\"ğŸ¥ ê°ë…:\", output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5c8de",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 1-3 : FewShotPromptTemplateê³¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ í™œìš© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff08c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ: ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€, sLLM, AIëª¨ë¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate, \n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸: ë³€ìˆ˜ëª…ì„ examplesì— ë§ì¶°ì„œ news, keywordsë¡œ ë³€ê²½\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{news}\"),\n",
    "    (\"ai\", \"í‚¤ì›Œë“œ: {keywords}\")\n",
    "])\n",
    "\n",
    "# 2. ì˜ˆì‹œ ë°ì´í„°\n",
    "examples = [\n",
    "    {\n",
    "        \"news\": \"ì‚¼ì„±ì „ìê°€ ì°¨ì„¸ëŒ€ ê³ ì„±ëŠ¥ HBM4 ë©”ëª¨ë¦¬ ê°œë°œì— ì°©ìˆ˜í–ˆë‹¤. ì´ë²ˆ ì œí’ˆì€ AI ì„œë²„ì™€ ë°ì´í„° ì„¼í„°ì—ì„œ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.\",\n",
    "        \"keywords\": \"ì‚¼ì„±ì „ì, HBM4, AIì„œë²„\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"í•œêµ­ì€í–‰ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ë™ê²°í•˜ë©´ì„œ ì˜¬í•´ í•˜ë°˜ê¸° ê²½ê¸° íšŒë³µì— ëŒ€í•œ ê¸°ëŒ€ê°€ ì»¤ì§€ê³  ìˆë‹¤. ì†Œë¹„ìë¬¼ê°€ëŠ” ì—¬ì „íˆ ë†’ì€ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆë‹¤.\",\n",
    "        \"keywords\": \"í•œêµ­ì€í–‰, ê¸°ì¤€ê¸ˆë¦¬, ì†Œë¹„ìë¬¼ê°€\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"ì •ë¶€ëŠ” ì´ë²ˆ êµ­ë¬´íšŒì˜ì—ì„œ ì²­ë…„ ì¼ìë¦¬ ì°½ì¶œê³¼ ê´€ë ¨ëœ 2025ë…„ ì •ì±… ë¡œë“œë§µì„ ë°œí‘œí–ˆë‹¤. ë””ì§€í„¸ ì‚°ì—…ê³¼ ì¹œí™˜ê²½ ì—ë„ˆì§€ ë¶„ì•¼ê°€ í•µì‹¬ìœ¼ë¡œ í¬í•¨ë˜ì—ˆë‹¤.\",\n",
    "        \"keywords\": \"ì •ë¶€, ì²­ë…„ì¼ìë¦¬, ì¹œí™˜ê²½ì—ë„ˆì§€\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"ì „ ì„¸ê³„ì ìœ¼ë¡œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ìœ ì—”ì€ ê°êµ­ì— ê¸°í›„ë³€í™” ëŒ€ì‘ ê°•í™”ë¥¼ ì´‰êµ¬í–ˆë‹¤. íŠ¹íˆ ì„ ì§„êµ­ì˜ ì±…ì„ì´ ê°•ì¡°ë˜ê³  ìˆë‹¤.\",\n",
    "        \"keywords\": \"ì´ì‚°í™”íƒ„ì†Œ, ê¸°í›„ë³€í™”, ìœ ì—”\"\n",
    "    }\n",
    "]\n",
    "# 3. Few-Shot Prompt êµ¬ì„±\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 4. ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 5. LLM ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 6. ì²´ì¸ ìƒì„±\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 7. í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ ì‹¤í–‰\n",
    "# test_news = \"\"\"í•œêµ­ì€í–‰ì€ 6ì›” ê¸ˆìœµí†µí™”ìœ„ì›íšŒ íšŒì˜ì—ì„œ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ 3.50%ë¡œ ìœ ì§€í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.  \n",
    "# ì´ë²ˆ ê²°ì •ì€ ë¬¼ê°€ ìƒìŠ¹ë¥  ë‘”í™”ì™€ ê²½ê¸° ë¶ˆí™•ì‹¤ì„± ì‚¬ì´ì—ì„œ ê· í˜•ì„ ê³ ë ¤í•œ ê²°ê³¼ë¡œ í•´ì„ë©ë‹ˆë‹¤.  \n",
    "# ì´ì°½ìš© ì´ì¬ëŠ” í–¥í›„ ê²½ì œ ì§€í‘œì™€ ëŒ€ì™¸ ì—¬ê±´ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ê²ƒì´ë¼ê³  ë°í˜”ìŠµë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "# test_news = \"\"\"\"ì œë¯¸ë‚˜ì´ 2.0 í”Œë˜ì‹œëŠ” í˜„ì¬ êµ¬ê¸€ AI ìŠ¤íŠœë””ì˜¤(Google AI Studio) ë° ë²„í…ìŠ¤ AI(Vertex AI)ì—ì„œ ì œë¯¸ë‚˜ì´ APIë¥¼ í†µí•´ ê°œë°œìì—ê²Œ ì‹¤í—˜ ëª¨ë¸ë¡œ ì œê³µë©ë‹ˆë‹¤. \n",
    "# ëª¨ë“  ê°œë°œìëŠ” ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ë° í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜(text-to-speech) ë° ë„¤ì´í‹°ë¸Œ ì´ë¯¸ì§€ ìƒì„±ì€ ì¼ë¶€ íŒŒíŠ¸ë„ˆë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. \n",
    "# ë‚´ë…„ 1ì›”ì—ëŠ” ë” ë§ì€ ëª¨ë¸ ì‚¬ì´ì¦ˆì™€ í•¨ê»˜ ì¼ë°˜ì— ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.\" \"\"\"\n",
    "\n",
    "test_news = \"\"\"[ì´ë°ì¼ë¦¬ ìœ¤ì •í›ˆ ê¸°ì] êµ­ì‚° ì¸ê³µì§€ëŠ¥(AI) ì¸í”„ë¼ ì „ë¬¸ê¸°ì—… ëª¨ë ˆ(Moreh)ì˜ ìíšŒì‚¬ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ê°€ ê·¸ë˜í”½ì²˜ë¦¬ì¥ì¹˜(GPU) 1ê°œë¡œ ì¶”ë¡ ì´ ê°€ëŠ¥í•œ ì†Œí˜•ì–¸ì–´ëª¨ë¸(sLLM)ì„ ìµœì´ˆë¡œ ê³µê°œí–ˆë‹¤. ì €ì „ë ¥ìœ¼ë¡œ êµ¬ë™ë˜ê³  ìŠˆí¼ì»´í“¨í„° ì—†ì´ ìš´ì˜ì´ ê°€ëŠ¥í•œ ì¥ì ì„ ë°”íƒ•ìœ¼ë¡œ êµ­ë‚´ì™¸ AI ìƒíƒœê³„ ê³µëµì— ë‚˜ì„ ë‹¤ëŠ” ê³„íšì´ë‹¤.\n",
    "\n",
    "\n",
    "ì„ì •í™˜ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ìŠ¤ ëŒ€í‘œê°€ 10ì¼ ì„œìš¸ ê°•ë‚¨êµ¬ ì¡°ì„ íŒ°ë¦¬ìŠ¤ì—ì„œ ì—´ë¦° â€˜ë ˆë…¸ë³´ í…Œí¬ë°ì´â€™ì—ì„œ sLLM ëª¨ë¸ â€˜ëª¨í‹°í”„ 2.6Bâ€™ë¥¼ ì†Œê°œí•˜ê³  ìˆë‹¤.(ì‚¬ì§„=ìœ¤ì •í›ˆ ê¸°ì)\n",
    "ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ëŠ” 10ì¼ ë ˆë…¸ë³´ í…Œí¬ë°ì´ì— ì°¸ì„í•´ í”„ë¡¬ ìŠ¤í¬ë˜ì¹˜(from scratchÂ·ë°‘ë°”ë‹¥ë¶€í„°) ê°œë°œí•œ íŒŒìš´ë°ì´ì…˜ sLLM â€˜ëª¨í‹°í”„ 2.6Bâ€™ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ í—ˆê¹…í˜ì´ìŠ¤ì— ê³µê°œí–ˆë‹¤ê³  ë°í˜”ë‹¤. ì´ ëª¨ë¸ì€ AMDê°€ ê°œë°œí•œ ì¸ìŠ¤í…”ë¼ë¥¼ ì œì™¸í•˜ê³  AMD ì¸ìŠ¤íŒ…íŠ¸ MI250 GPU ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„í•œ ìµœì´ˆì˜ AI íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "ì„ì •í™˜ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ìŠ¤ ëŒ€í‘œëŠ” â€œsLLMì€ ì €ì „ë ¥ìœ¼ë¡œ êµ¬ë™ë˜ê³  ìŠˆí¼ì»´í“¨í„° ì—†ì´ ìš´ì˜ì´ ê°€ëŠ¥í•´ ë¹„ìš© íš¨ìœ¨ì„±ì´ ë§¤ìš° ë†’ì•„ ì‹¤ì œ ì‚°ì—… í˜„ì¥ì—ì„œ ë‹¤ì–‘í•œ ì ìš©ì´ ê°€ëŠ¥í•´ ì„±ì¥ ì ì¬ë ¥ì´ ë§¤ìš° í¬ë‹¤â€ë©´ì„œ â€œì´ë²ˆì— ì„ ë³´ì¸ ëª¨í‹°í”„2.6Bë¥¼ í™œìš©í•´ ìš°ë¦¬ ì¼ìƒì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜¨ë””ë°”ì´ìŠ¤ AI, ì—ì´ì „í‹± AI ëª¨ë¸ë¡œ ë°œì „ì‹œì¼œ ë‚˜ê°ˆ ê²ƒâ€ì´ë¼ê³  ê°•ì¡°í–ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì— ëª¨í‹°í”„ê°€ ê³µê°œí•œ sLLMì€ ëª¨íšŒì‚¬ì¸ ëª¨ë ˆê°€ ì„¤ë¦½ ì´ˆê¸°ë¶€í„° ì¶”êµ¬í•´ì˜¨ GPU ìì›ì˜ íš¨ìœ¨ì  ì‚¬ìš©ê³¼ í´ëŸ¬ìŠ¤í„°ë§ SW ìµœì í™” ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨í‹°í”„ì—ì„œ ê°œë°œí•œ ê²½ëŸ‰í™”ëœ ê³ ì„±ëŠ¥ AIëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "ëª¨ë ˆëŠ” ì‘ë…„ 12ì›” ì˜¤í”ˆAI GPT-4ì˜ í•œêµ­ì–´ ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ëŠ” 1020ì–µ ë§¤ê°œë³€ìˆ˜ ê·œëª¨ì˜ í•œêµ­ì–´ íŠ¹í™” ê³ ì„±ëŠ¥ LLMì„ ê°œë°œí–ˆê³ , ì˜¬í•´ 2ì›”ë¶€í„°ëŠ” ë²•ì¸ì„ ë…ë¦½í•´ AMD GPU ê¸°ë°˜ì˜ AIëª¨ë¸ ê°œë°œì— í˜ì¨ì™”ë‹¤.\n",
    "\n",
    "ëª¨í‹°í”„ëŠ” 26ì–µê°œ ë§¤ê°œë³€ìˆ˜ë¡œ êµ¬ì„±ëœ ëª¨í‹°í”„ 2.6Bê°€ ê¸€ë¡œë²Œ sLLMê³¼ ë¹„êµí•´ë„ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë‹¤ê³  ë°í˜”ë‹¤.\n",
    "\n",
    "ê° ê°œë°œì‚¬ê°€ ê³µê°œí•œ í…Œí¬ë‹ˆì»¬ ë¦¬í¬íŠ¸ì˜ ì ìˆ˜ì™€ ì„¤ì •ê°’ì„ ë™ì¼í•˜ê²Œ ì ìš©í•´ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ë¥¼ ì‚°ì¶œí•œ ê²°ê³¼ â€˜ëª¨í‹°í”„ 2.6Bâ€™ëŠ” 70ì–µ ê°œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë¯¸ìŠ¤íŠ¸ë„ 7B ëŒ€ë¹„ 134%ì˜ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. íŠ¹íˆ ê³ ì„±ëŠ¥ì„ ìš”í•˜ëŠ” ê³ ë‚œë„ ìˆ˜í•™ ë° ê³¼í•™, ì½”ë”© ëŠ¥ë ¥ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆë‹¤. ë™ê¸‰ì¸ 1B~3B ëª¨ë¸ê³¼ì˜ ë¹„êµì—ì„œë„ êµ¬ê¸€ ì ¬ë§ˆ1(2B) ëŒ€ë¹„ 191%, ë©”íƒ€ ë¼ë§ˆ 3.2(1B) ëŒ€ë¹„ 139%, AMD ì¸ìŠ¤í…”ë¼(3B) ëŒ€ë¹„ 112%, ì•Œë¦¬ë°”ë°” íì› 2.5(3B) 104%ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.\n",
    "\n",
    "â€˜ëª¨í‹°í”„ 2.6Bâ€™ëŠ” ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ì„ ê°•í™”í•œ ì ì´ ê°€ì¥ í° ê¸°ìˆ ì  íŠ¹ì§•ì´ë‹¤. ì˜ëª»ëœ ë¬¸ë§¥ì„ ì°¸ê³ í•´ ë¶€ì •í™•í•œ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì¤„ì´ê³ , í•„ìˆ˜ì ì¸ í•µì‹¬ ë¬¸ë§¥ì— ì§‘ì¤‘í•˜ë„ë¡ ì„¤ê³„í–ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) êµ¬ì¡°ì˜ í•µì‹¬ì¸ ì–´í…ì…˜(Attention) ê¸°ìˆ ì„ ë³´ë‹¤ ì •êµí•˜ê²Œ í™œìš©í•´ ì¢€ ë” ì ì ˆí•˜ê²Œ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì ìš©í–ˆë‹¤.\n",
    "\n",
    "\n",
    "ëª¨í‹°í”„ê°€ ë§Œë“  sLLM ëª¨ë¸ì„ êµ¬ê¸€, MS, ì•Œë¦¬ë°”ë°” ë“±ì˜ ë™ê¸‰ ì´ìƒì˜ ëª¨ë¸ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œ(ì‚¬ì§„=ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€)\n",
    "ëª¨ë ˆëŠ” ëª¨í‹°í”„ê°€ ê³µê°œí•œ sLLMìœ¼ë¡œ êµ­ë‚´ AX ì‹œì¥ ì§„ì¶œì„ í•˜ëŠ” ë™ì‹œì— ë ˆë…¸ë²„Â·AMDì™€ íŒŒíŠ¸ë„ˆì‹­ì„ ë§ºê³  AI ë°ì´í„°ì„¼í„° ì†”ë£¨ì…˜ ì‹œì¥ ì§„ì¶œë„ ì¶”ì§„í•˜ê³  ìˆë‹¤. í˜„ì¬ ì¤‘êµ­, ì¸ë„, ì¼ë³¸ ë“± ì‹œì¥ì—ì„œ 10ì—¬ ê³³ì˜ ê³ ê°ì‚¬ê°€ ë„ì…ì„ ê²€í†  ì¤‘ì´ë‹¤.\n",
    "\n",
    "ì¡°í˜•ê·¼ ëª¨ë ˆ ìµœê³ ì „ëµì±…ì„ì(CSO)ëŠ” â€œëª¨ë ˆëŠ” ì—”ë¹„ë””ì•„ ì˜ì¡´ ì—†ì´ AMDì™€ í˜‘ë ¥í•´ íš¨ìœ¨ì ì¸ AIì¸í”„ë¼ë¥¼ ë§Œë“¤ì–´ì„œ ê²€ì¦ì„ ë§ˆì³¤ë‹¤â€ë©° â€œë§ì€ ê¸°ì—…ì´ ì €í¬ì˜ ì¸í”„ë¼ SWì™€ ê¸°ìˆ ì„ í™œìš©í•´ ê³ íš¨ìœ¨ì˜ ê²½ì œì„± ìˆëŠ” AIë¥¼ ë§Œë“¤ì–´ ì£¼ê¸¸ ë°”ë€ë‹¤â€ê³  ë§í–ˆë‹¤.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 8. ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": test_news})\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1159f3",
   "metadata": {},
   "source": [
    "# ë¬¸ì œ 2-1 : ì½¤ë§ˆ êµ¬ë¶„ ë¦¬ìŠ¤íŠ¸ íŒŒì„œ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d2d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìœ ëª…í•œ ë¶€ì‚°ì—ì„œ ë§›ìˆëŠ” ë§›ì§‘ ë‹¤ì„¯ ê°€ì§€ ëª©ë¡ì…ë‹ˆë‹¤.\n",
      "['ë¶€ì‚° ê°œë¯¸ì§‘', 'ë¶€ì‚° ì‚¼ì§„ì–´ë¬µ', 'ë¶€ì‚° ë°€ì–‘ ë¼ì§€êµ­ë°¥', 'ë¶€ì‚° ìê°ˆì¹˜ì‹œì¥', 'ë¶€ì‚° ë•ì·¨ì›']\n",
      "'./data/korea_ë¶€ì‚°ì—ì„œ ë§›ìˆëŠ” ë§›ì§‘.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import httpx\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "format_instructions = \"ê²°ê³¼ëŠ” Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ì˜ˆ: ['í•­ëª©1', 'í•­ëª©2', 'í•­ëª©3', 'í•­ëª©4', 'í•­ëª©5']\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í•œêµ­ì—ì„œ ìœ ëª…í•œ {subject} ë‹¤ì„¯ ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "subject = \"ë¶€ì‚°ì—ì„œ ë§›ìˆëŠ” ë§›ì§‘\"\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "try:\n",
    "    result = chain.invoke({\"subject\": subject})\n",
    "    output_text = result.content if hasattr(result, \"content\") else str(result)\n",
    "except httpx.RequestError as e:\n",
    "    print(f\"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"\n",
    "\n",
    "# ì‘ë‹µì—ì„œ ë¦¬ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "# 1) ```python ... ``` ì½”ë“œ ë¸”ë¡ ë‚´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "code_block_match = re.search(r\"```python\\s*\\n(.+?)\\n```\", output_text, re.DOTALL)\n",
    "if code_block_match:\n",
    "    code_block_content = code_block_match.group(1)\n",
    "    # ë¦¬ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ì¤„ë§Œ ì¶”ì¶œ (ë³´í†µ famous_cars = [...] ê°™ì€ í˜•ì‹)\n",
    "    list_match = re.search(r\"\\[.*\\]\", code_block_content, re.DOTALL)\n",
    "    if list_match:\n",
    "        list_str = list_match.group(0)\n",
    "    else:\n",
    "        list_str = \"\"\n",
    "else:\n",
    "    # ì½”ë“œë¸”ë¡ ì—†ìœ¼ë©´ ê·¸ëƒ¥ í…ìŠ¤íŠ¸ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸° ì‹œë„\n",
    "    list_match = re.search(r\"\\[.*\\]\", output_text, re.DOTALL)\n",
    "    list_str = list_match.group(0) if list_match else \"\"\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì´ ìˆìœ¼ë©´ íŒŒì‹± ì‹œë„\n",
    "if list_str:\n",
    "    try:\n",
    "        items = ast.literal_eval(list_str)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        items = [output_text]\n",
    "else:\n",
    "    print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ.\")\n",
    "    items = [output_text]\n",
    "\n",
    "print(f\"í•œêµ­ì˜ ìœ ëª…í•œ {subject} ë‹¤ì„¯ ê°€ì§€ ëª©ë¡ì…ë‹ˆë‹¤.\")\n",
    "print(items)\n",
    "\n",
    "csv_filename = f\"./data/korea_{subject}.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([subject])\n",
    "    for item in items:\n",
    "        writer.writerow([item.strip()])\n",
    "\n",
    "print(f\"'{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbc44c",
   "metadata": {},
   "source": [
    "### 2-2 ì˜í™” ë¦¬ë·° ê°ì • ë¶„ì„ê¸°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f919a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\n",
      "Select one of the following options: ê¸ì •, ë¶€ì •, ë³´í†µ\n",
      "input_variables=['text'] input_types={} partial_variables={'format_instructions': 'Select one of the following options: ê¸ì •, ë¶€ì •, ë³´í†µ'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], input_types={}, partial_variables={}, template='\\në‹¹ì‹ ì€ ì˜í™” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\në‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\\n\\ní…ìŠ¤íŠ¸: \"{text}\"\\n\\n{format_instructions}\\n\\nì¤‘ìš” ê·œì¹™:\\n1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ë³´í†µí†µ\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\\n2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\\n3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\\n4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\\n\\në‹µë³€:'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "\n",
    "# ê°ì • í´ë˜ìŠ¤ ì •ì˜ (Enum)\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ë³´í†µ\"\n",
    "\n",
    "# EnumOutputParser ì´ˆê¸°í™”\n",
    "enumParser = EnumOutputParser(enum=Sentiment)\n",
    "format_instructions = enumParser.get_format_instructions()\n",
    "\n",
    "print(\"ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì˜í™” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ì¤‘ìš” ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ë³´í†µí†µ\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n",
    "3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5efdc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ 6ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# OutputFixingParserë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=enumParser, llm=model)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "texts = [\n",
    "    \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ ë§¤ìš° í›Œë¥­í•˜ê³  ìŠ¤í† ë¦¬ë„ ê°ë™ì ì´ì—ˆì–´ìš”.\",\n",
    "    \"ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì˜ì§€ë„ ì¢‹ì§€ë„ ì•Šì•„ìš”ìš”\",\n",
    "    \"ì •ë§ ê°ë™ì ì´ì—ˆì–´ìš”. ëˆˆë¬¼ì´ ë‚¬ìŠµë‹ˆë‹¤.\",\n",
    "    \"ê¸°ëŒ€ ì´í•˜ì˜€ê³ , ì§€ë£¨í–ˆì–´ìš”.\",\n",
    "    \"í•œ ë²ˆì¯¤ ë³´ê¸°ì—” ê´œì°®ì€ ìˆ˜ì¤€ì´ì—ìš”.\"\n",
    "    \"ë³¼ë§Œì€ í–ˆì§€ë§Œ ë‹¤ì‹œ ë³´ê³  ì‹¶ì§„ ì•Šì•„ìš”.\",\n",
    "]\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ {len(texts)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b71f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\n",
      "\n",
      "1.ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "2.ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ ë§¤ìš° í›Œë¥­í•˜ê³  ìŠ¤í† ë¦¬ë„ ê°ë™ì ì´ì—ˆì–´ìš”.\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "3.ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì˜ì§€ë„ ì¢‹ì§€ë„ ì•Šì•„ìš”ìš”\n",
      "   ê°ì •: ë³´í†µ \n",
      "\n",
      "4.ì •ë§ ê°ë™ì ì´ì—ˆì–´ìš”. ëˆˆë¬¼ì´ ë‚¬ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "5.ê¸°ëŒ€ ì´í•˜ì˜€ê³ , ì§€ë£¨í–ˆì–´ìš”.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "6.í•œ ë²ˆì¯¤ ë³´ê¸°ì—” ê´œì°®ì€ ìˆ˜ì¤€ì´ì—ìš”.ë³¼ë§Œì€ í–ˆì§€ë§Œ ë‹¤ì‹œ ë³´ê³  ì‹¶ì§„ ì•Šì•„ìš”.\n",
      "   ê°ì •: ë³´í†µ \n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "ì„±ê³µ: 6/6 (100.0%)\n",
      "ì‹¤íŒ¨: 0/6\n"
     ]
    }
   ],
   "source": [
    "# ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
    "def safe_sentiment_analysis(text, use_fixing_parser=True):\n",
    "    \"\"\"ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ - ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨\"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ ì²´ì¸ ìƒì„±\n",
    "        chain = prompt | model | (fixing_parser if use_fixing_parser else enumParser)\n",
    "        \n",
    "        # ë¶„ì„ ì‹¤í–‰\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result, None\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        return None, f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"ì¼ë°˜ ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "\n",
    "# ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰ (API í‚¤ í•„ìš”)\n",
    "def run_sentiment_analysis():\n",
    "    \"\"\"ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_count = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{i}.{text}\")\n",
    "        \n",
    "        # OutputFixingParser ì‚¬ìš©\n",
    "        result, error = safe_sentiment_analysis(text, use_fixing_parser=True)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   ê°ì •: {result.value} \")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   ì˜¤ë¥˜: {error} \")\n",
    "            \n",
    "            # ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„\n",
    "            print(\"   ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„...\")\n",
    "            result2, error2 = safe_sentiment_analysis(text, use_fixing_parser=False)\n",
    "            \n",
    "            if result2:\n",
    "                print(f\"   ê°ì •: {result2.value} (ê¸°ë³¸ íŒŒì„œ ì„±ê³µ)\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"   ì¬ì‹œë„ ì‹¤íŒ¨: {error2} \")\n",
    "    \n",
    "    print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "    print(f\"ì‹¤íŒ¨: {total_count-success_count}/{total_count}\")\n",
    "\n",
    "# ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)\n",
    "try:\n",
    "    run_sentiment_analysis()\n",
    "except Exception as e:\n",
    "    print(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:\")\n",
    "    print(\"ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    print(f\"ì˜¤ë¥˜ ìƒì„¸: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c91c0",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2-3: í•™ìƒ ì •ë³´ êµ¬ì¡°í™” ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ffb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0637facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ë°•ì§€ì˜\",\n",
      "    \"age\": 25,\n",
      "    \"major\": \"ì¸ê³µì§€ëŠ¥í•™ê³¼\",\n",
      "    \"hobiies\": \"ë…ì„œ, ìš”ë¦¬, ë°ì´í„° ë¶„ì„\",\n",
      "    \"goal\": \"ë¯¸ë˜ì—ëŠ” AI ì „ë¬¸ê°€ê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œ.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "# 1. ì¶œë ¥ êµ¬ì¡° ì •ì˜\n",
    "class Profile(BaseModel):\n",
    "    name: str = Field(description=\"ë°•ì§€ì˜\") #ê¹€ë¯¼ìˆ˜ // ì´ì„œì—°\n",
    "    age: int = Field(description=\"25\") #22 // #30\n",
    "    major: str = Field(description=\"ì¸ê³µì§€ëŠ¥í•™ê³¼\") #ì»´í“¨í„°ê³µí•™ // ë°”ì´ì˜¤ë©”ë””ì»¬ ì—”ì§€ë‹ˆì–´ë§\n",
    "    hobbies: List[str] = Field(description=\"ë…ì„œ, ìš”ë¦¬, ë°ì´í„° ë¶„ì„\") #ê²Œì„í•˜ê¸°,ì˜í™”ë³´ê¸°,ì½”ë”©  // ì˜ë£Œ ê¸°ê¸° ê°œë°œê³¼ í—¬ìŠ¤í…Œí¬\n",
    "    goal: str = Field(description=\"ë¯¸ë˜ì—ëŠ” AI ì „ë¬¸ê°€ê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œ.\") #í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒ // ì˜ë£Œ í˜„ì¥ì˜ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì—”ì§€ë‹ˆì–´ë¡œ ì„±ì¥ì´ ëª©í‘œ.\n",
    "\n",
    "# 2. íŒŒì„œ ìƒì„±\n",
    "parser = PydanticOutputParser(pydantic_object=Profile)\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œì…ë‹ˆë‹¤. ì •ë³´ë¥¼ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\"),\n",
    "    (\"human\", \"{input_text}\\n\\n{format_instructions}\")\n",
    "])\n",
    "\n",
    "# âœ… 4. ëª¨ë¸ ì„¤ì • (Groq API ì‚¬ìš©)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 5. ì‚¬ìš©ì ì…ë ¥\n",
    "user_input = (\n",
    "    # \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¹€ë¯¼ìˆ˜ì´ê³  22ì‚´ì…ë‹ˆë‹¤. ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ìˆì–´ìš”. \"\n",
    "    # \"ì·¨ë¯¸ë¡œëŠ” ê²Œì„í•˜ê¸°, ì˜í™”ë³´ê¸°, ì½”ë”©ì„ ì¢‹ì•„í•©ë‹ˆë‹¤. \"\n",
    "    # \"ì•ìœ¼ë¡œ í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”! 25ì‚´ ì¸ê³µì§€ëŠ¥í•™ê³¼ ì „ê³µìƒ ë°•ì§€ì˜ì…ë‹ˆë‹¤. \"\n",
    "    \"ì·¨ë¯¸ëŠ” ë…ì„œ, ìš”ë¦¬, ë°ì´í„° ë¶„ì„ì´ë©°\"\n",
    "    \"ë¯¸ë˜ì—ëŠ” AI ì „ë¬¸ê°€ê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    # \"ì´ì„œì—°ì…ë‹ˆë‹¤. 30ì„¸ë¡œ ë°”ì´ì˜¤ë©”ë””ì»¬ ì—”ì§€ë‹ˆì–´ë§ì„ ì „ê³µ ì¤‘ì´ë©°\"\n",
    "    # \"ì£¼ìš” ê´€ì‹¬ì‚¬ëŠ” ì˜ë£Œ ê¸°ê¸° ê°œë°œê³¼ í—¬ìŠ¤í…Œí¬ì…ë‹ˆë‹¤.\"\n",
    "    # \"ì˜ë£Œ í˜„ì¥ì˜ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì—”ì§€ë‹ˆì–´ë¡œ ì„±ì¥í•˜ê³ ì í•©ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# 6. ì²´ì¸ ì‹¤í–‰\n",
    "chain = prompt | model | parser\n",
    "result = chain.invoke({\n",
    "    \"input_text\": user_input,\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "# âœ… 7. ì˜ˆì‹œ ì¶œë ¥ êµ¬ì¡°ì— ë§ê²Œ ì¶œë ¥\n",
    "output = {\n",
    "    \"name\": result.name,\n",
    "    \"age\": result.age,\n",
    "    \"major\": result.major,\n",
    "    \"hobiies\": \", \".join(result.hobbies),  # ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰¼í‘œë¡œ ì—°ê²°í•œ ë¬¸ìì—´ë¡œ ë³€ê²½\n",
    "    \"goal\": result.goal\n",
    "}\n",
    "\n",
    "print(json.dumps(output, ensure_ascii=False, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
