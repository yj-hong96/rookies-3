{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1532373",
   "metadata": {},
   "source": [
    "### 1-1ë²ˆ ê¸°ë³¸ ì²´ì¸ ë§Œë“¤ê¸° -AI ìš”ë¦¬ì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3feb0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f98dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5c5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ìš”ë¦¬ì‚¬ ì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ìš”ë¦¬ì‚¬ ì…ë‹ˆë‹¤.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"ê³„ë€ê³¼ ë°¥ ê¹€ì¹˜ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…ê³¼ ìŒì‹ì„ ì¶”ì²œí•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de31bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000250C93C7890> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000250C93C7C50> root_client=<openai.OpenAI object at 0x00000250C93C5E50> root_async_client=<openai.AsyncOpenAI object at 0x00000250C93C7390> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c975600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ê³„ë€ê³¼ ë°¥, ê¹€ì¹˜ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¡œ 'ê³„ë€ ê¹€ì¹˜ë°¥'ì„ ì¶”ì²œí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì¬ë£Œ ì¤€ë¹„**: ê³„ë€ 2ê°œ, ë°¥ 1ê³µê¸°, ê¹€ì¹˜ 1/2ì»µ, ì°¸ê¸°ë¦„ 1í‹°ìŠ¤í‘¼, ì†Œê¸ˆ 1/2í‹°ìŠ¤í‘¼, í›„ì¶” 1/4í‹°ìŠ¤í‘¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
      "2.  **ê¹€ì¹˜ ë‹¤ë“¬ê¸°**: ê¹€ì¹˜ë¥¼ ì˜ê²Œ ì°ì–´ì£¼ì„¸ìš”. \n",
      "3.  **ê³„ë€ í’€ê¸°**: ê³„ë€ì„ ê¹¨ëœ¨ë ¤ ê·¸ë¦‡ì— ë„£ê³ , ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•œ ë’¤ ì˜ í’€ì–´ì¤ë‹ˆë‹¤.\n",
      "4.  **ê³„ë€ í”„ë¼ì´**: íŒ¬ì— ì°¸ê¸°ë¦„ì„ ë‘ë¥´ê³  ê³„ë€ì„ ë„£ì–´ ìŠ¤í¬ë¨ë¸” ì—ê·¸ì²˜ëŸ¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. \n",
      "5.  **ë°¥ê³¼ ê¹€ì¹˜ ì„ê¸°**: ë°¥ì— ì°ì–´ ë†“ì€ ê¹€ì¹˜ë¥¼ ë„£ê³  ì˜ ì„ì–´ì¤ë‹ˆë‹¤.\n",
      "6.  **ì™„ì„±**: ì´ì œ í”„ë¼ì´íŒ¬ì— ë§Œë“¤ì–´ ë†“ì€ ê³„ë€ê³¼ ê¹€ì¹˜ë°¥ì„ ì„ì–´ì¤ë‹ˆë‹¤. \n",
      "7.  **ë§ˆë¬´ë¦¬**: ë§›ìˆëŠ” ê³„ë€ ê¹€ì¹˜ë°¥ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a2c97",
   "metadata": {},
   "source": [
    "### 1-2 2ë‹¨ê³„ ì²´ì¸ ë§Œë“¤ê¸° - ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "* ë¬¸ì œ ì„¤ëª… : ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” ì¥ë¥´ë¥¼ ì…ë ¥í•˜ë©´, ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ê·¸ì˜í™”ì˜ ì •ë³´(ê°ë…, ì¤„ê±°ë¦¬, ë“±ì¥ì¸ë¬¼)ë“¤ì„ ì•Œë ¤ì£¼ëŠ” 2ë‹¨ê³„ ì²´ì¸ì„ êµ¬í˜„í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "647e7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82efb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì˜í™”ê°í‰ì‚¬ ì…ë‹ˆë‹¤. ì¥ë¥´ì— ë§ëŠ” ìµœê³ ì˜ ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ì˜í™”ê°í‰ì‚¬ ì…ë‹ˆë‹¤. ì¥ë¥´ì— ë§ëŠ” ìµœê³ ì˜ ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78afa474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000250C96CB020> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000250C96CA8A0> root_client=<openai.OpenAI object at 0x00000250C96CB110> root_async_client=<openai.AsyncOpenAI object at 0x00000250C96CAD50> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#\n",
    "prompt3 = ChatPromptTemplate.from_template(\"{movie}  ê°ë…ì´ ëˆ„êµ¬ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c63673a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ ì¶”ì²œ ì˜í™”: ìŠ¤ë¦´ëŸ¬ ì˜í™” ì¤‘ 'ì˜¬ë“œ ë³´ì´'(2003)ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜¬ë“œ ë³´ì´ëŠ” í•œêµ­ ì˜í™”ê³„ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì˜í™” ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ì£¼ì¸ê³µì´ 15ë…„ê°„ ê°ê¸ˆëœ ì±„ë¡œ ê¸°ì–µì„ ìƒê³ , ê·¸ í›„ ê¸°ì–µì„ ë˜ì°¾ê³  ë³µìˆ˜ë¥¼ ì¤€ë¹„í•˜ëŠ” ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ ì˜í™”ëŠ” ì‹¬ë¦¬ ìŠ¤ë¦´ëŸ¬ ì¥ë¥´ì— ì†í•˜ë©°, ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ìŠ¤í† ë¦¬ì™€ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ë§ì€ íŒ¬ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " ì¶”ì²œí•˜ëŠ” ì˜í™”ëŠ” 'ì˜¬ë“œ ë³´ì´'(2003)ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ì¸ê³µì€ 15ë…„ê°„ ê°ê¸ˆëœ ì±„ë¡œ ê¸°ì–µì„ ìƒê³ , ê°ê¸ˆëœ ì´ìœ ë‚˜ ìì‹ ì˜ ê³¼ê±°ì— ëŒ€í•´ ì „í˜€ ëª¨ë¥´ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì–µì„ ë˜ì°¾ì€ í›„, ê·¸ëŠ” ìì‹ ì˜ ê°ê¸ˆê³¼ ë³µìˆ˜ë¥¼ ì¤€ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ìŠ¤í† ë¦¬ì™€ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ë§ì€ íŒ¬ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ¥ ê°ë…: ì˜¬ë“œ ë³´ì´ì˜ ê°ë…ì€ ë°•ì°¬ìš±ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ì •ì˜\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "chain3 = prompt3 | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "output1 = chain1.invoke({\"genre\": \"ìŠ¤ë¦´ëŸ¬\"})      # ì¥ë¥´ë¡œ ì˜í™” ì¶”ì²œ\n",
    "output2 = chain2.invoke({\"movie\": output1})       # ì¶”ì²œ ì˜í™”ë¡œ ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "output3 = chain3.invoke({\"movie\": output1})       # ì¶”ì²œ ì˜í™”ì˜ ê°ë… ì •ë³´\n",
    "\n",
    "print(\"ğŸ¬ ì¶”ì²œ ì˜í™”:\", output1)\n",
    "print(\"ğŸ“ ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", output2)\n",
    "print(\"ğŸ¥ ê°ë…:\", output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5c8de",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 1-3 : FewShotPromptTemplateê³¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ í™œìš© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff08c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ: ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€, sLLM, AIëª¨ë¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate, \n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸: ë³€ìˆ˜ëª…ì„ examplesì— ë§ì¶°ì„œ news, keywordsë¡œ ë³€ê²½\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{news}\"),\n",
    "    (\"ai\", \"í‚¤ì›Œë“œ: {keywords}\")\n",
    "])\n",
    "\n",
    "# 2. ì˜ˆì‹œ ë°ì´í„°\n",
    "examples = [\n",
    "    {\n",
    "        \"news\": \"ì‚¼ì„±ì „ìê°€ ì°¨ì„¸ëŒ€ ê³ ì„±ëŠ¥ HBM4 ë©”ëª¨ë¦¬ ê°œë°œì— ì°©ìˆ˜í–ˆë‹¤. ì´ë²ˆ ì œí’ˆì€ AI ì„œë²„ì™€ ë°ì´í„° ì„¼í„°ì—ì„œ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.\",\n",
    "        \"keywords\": \"ì‚¼ì„±ì „ì, HBM4, AIì„œë²„\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"í•œêµ­ì€í–‰ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ë™ê²°í•˜ë©´ì„œ ì˜¬í•´ í•˜ë°˜ê¸° ê²½ê¸° íšŒë³µì— ëŒ€í•œ ê¸°ëŒ€ê°€ ì»¤ì§€ê³  ìˆë‹¤. ì†Œë¹„ìë¬¼ê°€ëŠ” ì—¬ì „íˆ ë†’ì€ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆë‹¤.\",\n",
    "        \"keywords\": \"í•œêµ­ì€í–‰, ê¸°ì¤€ê¸ˆë¦¬, ì†Œë¹„ìë¬¼ê°€\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"ì •ë¶€ëŠ” ì´ë²ˆ êµ­ë¬´íšŒì˜ì—ì„œ ì²­ë…„ ì¼ìë¦¬ ì°½ì¶œê³¼ ê´€ë ¨ëœ 2025ë…„ ì •ì±… ë¡œë“œë§µì„ ë°œí‘œí–ˆë‹¤. ë””ì§€í„¸ ì‚°ì—…ê³¼ ì¹œí™˜ê²½ ì—ë„ˆì§€ ë¶„ì•¼ê°€ í•µì‹¬ìœ¼ë¡œ í¬í•¨ë˜ì—ˆë‹¤.\",\n",
    "        \"keywords\": \"ì •ë¶€, ì²­ë…„ì¼ìë¦¬, ì¹œí™˜ê²½ì—ë„ˆì§€\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"ì „ ì„¸ê³„ì ìœ¼ë¡œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ìœ ì—”ì€ ê°êµ­ì— ê¸°í›„ë³€í™” ëŒ€ì‘ ê°•í™”ë¥¼ ì´‰êµ¬í–ˆë‹¤. íŠ¹íˆ ì„ ì§„êµ­ì˜ ì±…ì„ì´ ê°•ì¡°ë˜ê³  ìˆë‹¤.\",\n",
    "        \"keywords\": \"ì´ì‚°í™”íƒ„ì†Œ, ê¸°í›„ë³€í™”, ìœ ì—”\"\n",
    "    }\n",
    "]\n",
    "# 3. Few-Shot Prompt êµ¬ì„±\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 4. ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 5. LLM ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 6. ì²´ì¸ ìƒì„±\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 7. í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ ì‹¤í–‰\n",
    "# test_news = \"\"\"í•œêµ­ì€í–‰ì€ 6ì›” ê¸ˆìœµí†µí™”ìœ„ì›íšŒ íšŒì˜ì—ì„œ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ 3.50%ë¡œ ìœ ì§€í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.  \n",
    "# ì´ë²ˆ ê²°ì •ì€ ë¬¼ê°€ ìƒìŠ¹ë¥  ë‘”í™”ì™€ ê²½ê¸° ë¶ˆí™•ì‹¤ì„± ì‚¬ì´ì—ì„œ ê· í˜•ì„ ê³ ë ¤í•œ ê²°ê³¼ë¡œ í•´ì„ë©ë‹ˆë‹¤.  \n",
    "# ì´ì°½ìš© ì´ì¬ëŠ” í–¥í›„ ê²½ì œ ì§€í‘œì™€ ëŒ€ì™¸ ì—¬ê±´ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ê²ƒì´ë¼ê³  ë°í˜”ìŠµë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "# test_news = \"\"\"\"ì œë¯¸ë‚˜ì´ 2.0 í”Œë˜ì‹œëŠ” í˜„ì¬ êµ¬ê¸€ AI ìŠ¤íŠœë””ì˜¤(Google AI Studio) ë° ë²„í…ìŠ¤ AI(Vertex AI)ì—ì„œ ì œë¯¸ë‚˜ì´ APIë¥¼ í†µí•´ ê°œë°œìì—ê²Œ ì‹¤í—˜ ëª¨ë¸ë¡œ ì œê³µë©ë‹ˆë‹¤. \n",
    "# ëª¨ë“  ê°œë°œìëŠ” ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ë° í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜(text-to-speech) ë° ë„¤ì´í‹°ë¸Œ ì´ë¯¸ì§€ ìƒì„±ì€ ì¼ë¶€ íŒŒíŠ¸ë„ˆë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. \n",
    "# ë‚´ë…„ 1ì›”ì—ëŠ” ë” ë§ì€ ëª¨ë¸ ì‚¬ì´ì¦ˆì™€ í•¨ê»˜ ì¼ë°˜ì— ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.\" \"\"\"\n",
    "\n",
    "test_news = \"\"\"[ì´ë°ì¼ë¦¬ ìœ¤ì •í›ˆ ê¸°ì] êµ­ì‚° ì¸ê³µì§€ëŠ¥(AI) ì¸í”„ë¼ ì „ë¬¸ê¸°ì—… ëª¨ë ˆ(Moreh)ì˜ ìíšŒì‚¬ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ê°€ ê·¸ë˜í”½ì²˜ë¦¬ì¥ì¹˜(GPU) 1ê°œë¡œ ì¶”ë¡ ì´ ê°€ëŠ¥í•œ ì†Œí˜•ì–¸ì–´ëª¨ë¸(sLLM)ì„ ìµœì´ˆë¡œ ê³µê°œí–ˆë‹¤. ì €ì „ë ¥ìœ¼ë¡œ êµ¬ë™ë˜ê³  ìŠˆí¼ì»´í“¨í„° ì—†ì´ ìš´ì˜ì´ ê°€ëŠ¥í•œ ì¥ì ì„ ë°”íƒ•ìœ¼ë¡œ êµ­ë‚´ì™¸ AI ìƒíƒœê³„ ê³µëµì— ë‚˜ì„ ë‹¤ëŠ” ê³„íšì´ë‹¤.\n",
    "\n",
    "\n",
    "ì„ì •í™˜ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ìŠ¤ ëŒ€í‘œê°€ 10ì¼ ì„œìš¸ ê°•ë‚¨êµ¬ ì¡°ì„ íŒ°ë¦¬ìŠ¤ì—ì„œ ì—´ë¦° â€˜ë ˆë…¸ë³´ í…Œí¬ë°ì´â€™ì—ì„œ sLLM ëª¨ë¸ â€˜ëª¨í‹°í”„ 2.6Bâ€™ë¥¼ ì†Œê°œí•˜ê³  ìˆë‹¤.(ì‚¬ì§„=ìœ¤ì •í›ˆ ê¸°ì)\n",
    "ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ëŠ” 10ì¼ ë ˆë…¸ë³´ í…Œí¬ë°ì´ì— ì°¸ì„í•´ í”„ë¡¬ ìŠ¤í¬ë˜ì¹˜(from scratchÂ·ë°‘ë°”ë‹¥ë¶€í„°) ê°œë°œí•œ íŒŒìš´ë°ì´ì…˜ sLLM â€˜ëª¨í‹°í”„ 2.6Bâ€™ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ í—ˆê¹…í˜ì´ìŠ¤ì— ê³µê°œí–ˆë‹¤ê³  ë°í˜”ë‹¤. ì´ ëª¨ë¸ì€ AMDê°€ ê°œë°œí•œ ì¸ìŠ¤í…”ë¼ë¥¼ ì œì™¸í•˜ê³  AMD ì¸ìŠ¤íŒ…íŠ¸ MI250 GPU ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„í•œ ìµœì´ˆì˜ AI íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "ì„ì •í™˜ ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€ìŠ¤ ëŒ€í‘œëŠ” â€œsLLMì€ ì €ì „ë ¥ìœ¼ë¡œ êµ¬ë™ë˜ê³  ìŠˆí¼ì»´í“¨í„° ì—†ì´ ìš´ì˜ì´ ê°€ëŠ¥í•´ ë¹„ìš© íš¨ìœ¨ì„±ì´ ë§¤ìš° ë†’ì•„ ì‹¤ì œ ì‚°ì—… í˜„ì¥ì—ì„œ ë‹¤ì–‘í•œ ì ìš©ì´ ê°€ëŠ¥í•´ ì„±ì¥ ì ì¬ë ¥ì´ ë§¤ìš° í¬ë‹¤â€ë©´ì„œ â€œì´ë²ˆì— ì„ ë³´ì¸ ëª¨í‹°í”„2.6Bë¥¼ í™œìš©í•´ ìš°ë¦¬ ì¼ìƒì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜¨ë””ë°”ì´ìŠ¤ AI, ì—ì´ì „í‹± AI ëª¨ë¸ë¡œ ë°œì „ì‹œì¼œ ë‚˜ê°ˆ ê²ƒâ€ì´ë¼ê³  ê°•ì¡°í–ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì— ëª¨í‹°í”„ê°€ ê³µê°œí•œ sLLMì€ ëª¨íšŒì‚¬ì¸ ëª¨ë ˆê°€ ì„¤ë¦½ ì´ˆê¸°ë¶€í„° ì¶”êµ¬í•´ì˜¨ GPU ìì›ì˜ íš¨ìœ¨ì  ì‚¬ìš©ê³¼ í´ëŸ¬ìŠ¤í„°ë§ SW ìµœì í™” ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨í‹°í”„ì—ì„œ ê°œë°œí•œ ê²½ëŸ‰í™”ëœ ê³ ì„±ëŠ¥ AIëª¨ë¸ì´ë‹¤.\n",
    "\n",
    "ëª¨ë ˆëŠ” ì‘ë…„ 12ì›” ì˜¤í”ˆAI GPT-4ì˜ í•œêµ­ì–´ ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ëŠ” 1020ì–µ ë§¤ê°œë³€ìˆ˜ ê·œëª¨ì˜ í•œêµ­ì–´ íŠ¹í™” ê³ ì„±ëŠ¥ LLMì„ ê°œë°œí–ˆê³ , ì˜¬í•´ 2ì›”ë¶€í„°ëŠ” ë²•ì¸ì„ ë…ë¦½í•´ AMD GPU ê¸°ë°˜ì˜ AIëª¨ë¸ ê°œë°œì— í˜ì¨ì™”ë‹¤.\n",
    "\n",
    "ëª¨í‹°í”„ëŠ” 26ì–µê°œ ë§¤ê°œë³€ìˆ˜ë¡œ êµ¬ì„±ëœ ëª¨í‹°í”„ 2.6Bê°€ ê¸€ë¡œë²Œ sLLMê³¼ ë¹„êµí•´ë„ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë‹¤ê³  ë°í˜”ë‹¤.\n",
    "\n",
    "ê° ê°œë°œì‚¬ê°€ ê³µê°œí•œ í…Œí¬ë‹ˆì»¬ ë¦¬í¬íŠ¸ì˜ ì ìˆ˜ì™€ ì„¤ì •ê°’ì„ ë™ì¼í•˜ê²Œ ì ìš©í•´ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ë¥¼ ì‚°ì¶œí•œ ê²°ê³¼ â€˜ëª¨í‹°í”„ 2.6Bâ€™ëŠ” 70ì–µ ê°œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë¯¸ìŠ¤íŠ¸ë„ 7B ëŒ€ë¹„ 134%ì˜ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. íŠ¹íˆ ê³ ì„±ëŠ¥ì„ ìš”í•˜ëŠ” ê³ ë‚œë„ ìˆ˜í•™ ë° ê³¼í•™, ì½”ë”© ëŠ¥ë ¥ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆë‹¤. ë™ê¸‰ì¸ 1B~3B ëª¨ë¸ê³¼ì˜ ë¹„êµì—ì„œë„ êµ¬ê¸€ ì ¬ë§ˆ1(2B) ëŒ€ë¹„ 191%, ë©”íƒ€ ë¼ë§ˆ 3.2(1B) ëŒ€ë¹„ 139%, AMD ì¸ìŠ¤í…”ë¼(3B) ëŒ€ë¹„ 112%, ì•Œë¦¬ë°”ë°” íì› 2.5(3B) 104%ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.\n",
    "\n",
    "â€˜ëª¨í‹°í”„ 2.6Bâ€™ëŠ” ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ì„ ê°•í™”í•œ ì ì´ ê°€ì¥ í° ê¸°ìˆ ì  íŠ¹ì§•ì´ë‹¤. ì˜ëª»ëœ ë¬¸ë§¥ì„ ì°¸ê³ í•´ ë¶€ì •í™•í•œ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì¤„ì´ê³ , í•„ìˆ˜ì ì¸ í•µì‹¬ ë¬¸ë§¥ì— ì§‘ì¤‘í•˜ë„ë¡ ì„¤ê³„í–ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) êµ¬ì¡°ì˜ í•µì‹¬ì¸ ì–´í…ì…˜(Attention) ê¸°ìˆ ì„ ë³´ë‹¤ ì •êµí•˜ê²Œ í™œìš©í•´ ì¢€ ë” ì ì ˆí•˜ê²Œ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì ìš©í–ˆë‹¤.\n",
    "\n",
    "\n",
    "ëª¨í‹°í”„ê°€ ë§Œë“  sLLM ëª¨ë¸ì„ êµ¬ê¸€, MS, ì•Œë¦¬ë°”ë°” ë“±ì˜ ë™ê¸‰ ì´ìƒì˜ ëª¨ë¸ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œ(ì‚¬ì§„=ëª¨í‹°í”„í…Œí¬ë†€ë¡œì§€)\n",
    "ëª¨ë ˆëŠ” ëª¨í‹°í”„ê°€ ê³µê°œí•œ sLLMìœ¼ë¡œ êµ­ë‚´ AX ì‹œì¥ ì§„ì¶œì„ í•˜ëŠ” ë™ì‹œì— ë ˆë…¸ë²„Â·AMDì™€ íŒŒíŠ¸ë„ˆì‹­ì„ ë§ºê³  AI ë°ì´í„°ì„¼í„° ì†”ë£¨ì…˜ ì‹œì¥ ì§„ì¶œë„ ì¶”ì§„í•˜ê³  ìˆë‹¤. í˜„ì¬ ì¤‘êµ­, ì¸ë„, ì¼ë³¸ ë“± ì‹œì¥ì—ì„œ 10ì—¬ ê³³ì˜ ê³ ê°ì‚¬ê°€ ë„ì…ì„ ê²€í†  ì¤‘ì´ë‹¤.\n",
    "\n",
    "ì¡°í˜•ê·¼ ëª¨ë ˆ ìµœê³ ì „ëµì±…ì„ì(CSO)ëŠ” â€œëª¨ë ˆëŠ” ì—”ë¹„ë””ì•„ ì˜ì¡´ ì—†ì´ AMDì™€ í˜‘ë ¥í•´ íš¨ìœ¨ì ì¸ AIì¸í”„ë¼ë¥¼ ë§Œë“¤ì–´ì„œ ê²€ì¦ì„ ë§ˆì³¤ë‹¤â€ë©° â€œë§ì€ ê¸°ì—…ì´ ì €í¬ì˜ ì¸í”„ë¼ SWì™€ ê¸°ìˆ ì„ í™œìš©í•´ ê³ íš¨ìœ¨ì˜ ê²½ì œì„± ìˆëŠ” AIë¥¼ ë§Œë“¤ì–´ ì£¼ê¸¸ ë°”ë€ë‹¤â€ê³  ë§í–ˆë‹¤.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 8. ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": test_news})\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1159f3",
   "metadata": {},
   "source": [
    "# ë¬¸ì œ 2-1 : ì½¤ë§ˆ êµ¬ë¶„ ë¦¬ìŠ¤íŠ¸ íŒŒì„œ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c06997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìœ ëª…í•œ ì¥ì†Œ/í™œë™/ìŒì‹ ëª©ë¡:\n",
      "ì‚¬ìš©ìê°€ ê´€ì‹¬ìˆëŠ” ë¶„ì•¼ë¥¼ 5ê°€ì§€ë¡œ ì œí•œí•´ì„œ ìŒì‹, ìŠ¤í¬ì¸ , ì˜í™”ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”.\n",
      "ê²°ê³¼ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•œêµ­ì–´ ëª©ë¡ìœ¼ë¡œ ì œê³µí•´ ë“œë¦´ê²Œìš”: ìŒì‹, ìŠ¤í¬ì¸ , ì˜í™”, ìŒì•…, ì—¬í–‰\n",
      "'./data/ì—°ìŠµë¬¸ì œ 2-1.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ë””ë ‰í„°ë¦¬ ìƒì„±\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# ì¶œë ¥ í¬ë§· ì§€ì¹¨ (í•œêµ­ì–´ ìš”ì²­)\n",
    "format_instructions = \"ê²°ê³¼ëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ í•œêµ­ì–´ ëª©ë¡ìœ¼ë¡œ ì œê³µí•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ë‹¤ì„¯ ê°€ì§€ {subject}ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ì²´ì¸ ì—°ê²°\n",
    "chain = prompt | model\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì£¼ì œ í•œêµ­ì–´ë¡œ ì„¤ì •\n",
    "result = chain.invoke({\"subject\": \"ì‚¬ìš©ìê°€ ê´€ì‹¬ìˆëŠ” ë¶„ì•¼ì¸ ìŒì‹,ìŠ¤í¬ì¸ ,ì˜í™”\"})\n",
    "\n",
    "# ì‘ë‹µ ì¶”ì¶œ\n",
    "output_text = result.content if hasattr(result, \"content\") else str(result)\n",
    "\n",
    "# ì¶œë ¥ í™•ì¸\n",
    "print(\"í•œêµ­ì˜ ìœ ëª…í•œ ì¥ì†Œ/í™œë™/ìŒì‹ ëª©ë¡:\")\n",
    "print(output_text)\n",
    "\n",
    "# CSV ì €ì¥\n",
    "csv_filename = \"./data/ì—°ìŠµë¬¸ì œ 2-1.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"ì¥ì†Œ/í™œë™/ìŒì‹\"])\n",
    "    for item in output_text.split(\",\"):\n",
    "        writer.writerow([item.strip()])\n",
    "\n",
    "print(f\"'{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed736bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìœ ëª…í•œ ìŒì‹ ëª©ë¡:\n",
      "['ë¹„ë¹”ë°¥', 'ë¶ˆê³ ê¸°', 'ê¹€ì¹˜ì°Œê°œ', 'ì‚¼ê³„íƒ•', 'ëƒ‰ë©´']\n",
      "ìŒì‹\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import httpx  # httpx ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ import\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "format_instructions = \"ê²°ê³¼ëŠ” Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ì˜ˆ: ['í•­ëª©1', 'í•­ëª©2', 'í•­ëª©3', 'í•­ëª©4', 'í•­ëª©5']\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í•œêµ­ì—ì„œ ìœ ëª…í•œ {subject} ë‹¤ì„¯ ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "subject = \"ìŒì‹\"\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "try:\n",
    "    result = chain.invoke({\"subject\": subject})\n",
    "    output_text = result.content if hasattr(result, \"content\") else str(result)\n",
    "except httpx.RequestError as e:\n",
    "    print(f\"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ê¸°ë³¸ê°’ ì„¤ì •\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ ë¶€ë¶„ ì¶”ì¶œ ë° íŒŒì‹±\n",
    "match = re.search(r\"\\[.*\\]\", output_text, re.DOTALL)\n",
    "if match:\n",
    "    list_str = match.group(0)\n",
    "    try:\n",
    "        items = ast.literal_eval(list_str)\n",
    "        items = [item for item in items if '.' not in item and 'python' not in item.lower()]\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        items = [output_text]\n",
    "else:\n",
    "    print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ.\")\n",
    "    items = [output_text]\n",
    "\n",
    "print(f\"í•œêµ­ì˜ ìœ ëª…í•œ {subject} ëª©ë¡:\")\n",
    "print(items)\n",
    "\n",
    "csv_filename = f\"./data/korea_{subject}.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([subject])\n",
    "    for item in items:\n",
    "        writer.writerow([item.strip()])\n",
    "\n",
    "print(subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d2d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìœ ëª…í•œ ê¸°ì—… ë‹¤ì„¯ ê°€ì§€ ëª©ë¡ì…ë‹ˆë‹¤.\n",
      "['ì‚¼ì„±ì „ì', 'LGì „ì', 'í˜„ëŒ€ìë™ì°¨', 'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤']\n",
      "'./data/korea_ê¸°ì—….csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import httpx\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "format_instructions = \"ê²°ê³¼ëŠ” Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ì˜ˆ: ['í•­ëª©1', 'í•­ëª©2', 'í•­ëª©3', 'í•­ëª©4', 'í•­ëª©5']\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í•œêµ­ì—ì„œ ìœ ëª…í•œ {subject} ë‹¤ì„¯ ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "subject = \"ê¸°ì—…\"\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "try:\n",
    "    result = chain.invoke({\"subject\": subject})\n",
    "    output_text = result.content if hasattr(result, \"content\") else str(result)\n",
    "except httpx.RequestError as e:\n",
    "    print(f\"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    output_text = \"[]\"\n",
    "\n",
    "# ì‘ë‹µì—ì„œ ë¦¬ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "# 1) ```python ... ``` ì½”ë“œ ë¸”ë¡ ë‚´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "code_block_match = re.search(r\"```python\\s*\\n(.+?)\\n```\", output_text, re.DOTALL)\n",
    "if code_block_match:\n",
    "    code_block_content = code_block_match.group(1)\n",
    "    # ë¦¬ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ì¤„ë§Œ ì¶”ì¶œ (ë³´í†µ famous_cars = [...] ê°™ì€ í˜•ì‹)\n",
    "    list_match = re.search(r\"\\[.*\\]\", code_block_content, re.DOTALL)\n",
    "    if list_match:\n",
    "        list_str = list_match.group(0)\n",
    "    else:\n",
    "        list_str = \"\"\n",
    "else:\n",
    "    # ì½”ë“œë¸”ë¡ ì—†ìœ¼ë©´ ê·¸ëƒ¥ í…ìŠ¤íŠ¸ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸° ì‹œë„\n",
    "    list_match = re.search(r\"\\[.*\\]\", output_text, re.DOTALL)\n",
    "    list_str = list_match.group(0) if list_match else \"\"\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì´ ìˆìœ¼ë©´ íŒŒì‹± ì‹œë„\n",
    "if list_str:\n",
    "    try:\n",
    "        items = ast.literal_eval(list_str)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        items = [output_text]\n",
    "else:\n",
    "    print(\"âš ï¸ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ.\")\n",
    "    items = [output_text]\n",
    "\n",
    "print(f\"í•œêµ­ì˜ ìœ ëª…í•œ {subject} ë‹¤ì„¯ ê°€ì§€ ëª©ë¡ì…ë‹ˆë‹¤.\")\n",
    "print(items)\n",
    "\n",
    "csv_filename = f\"./data/korea_{subject}.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([subject])\n",
    "    for item in items:\n",
    "        writer.writerow([item.strip()])\n",
    "\n",
    "print(f\"'{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
